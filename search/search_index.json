{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to PySHbundle","text":"<p>PySHbundle: A Python implementation of MATLAB codes SHbundle</p> <p>Our package, <code>PySHbundle</code> has been developed in a modularized manner. The package provides tools to process GRACE data, such as, the computation of anomalies, substitution of poor quality low degree coefficients, reducing noise in GRACE data using filtering approaches, signal leakage correction using <code>GDDC</code>, etc. In addition, the package provides a flexibility for future development and addition of further processing choices for handling GRACE data for hydrological application.</p> <p>It is hoped the contribution will make GRACE L2 data processing more accessible to a wider audience of young researchers. Our python package is titled <code>PySHbundle</code> and the working code can be accessed at GitHub. </p>"},{"location":"#how-to-install","title":"How to install","text":"<p><pre><code># clone the repository in order to access the notebooks and data\n$ git clone https://github.com/GESS-research-group/pyshbundle.git\n$ pip install .\n\n\n# The package is available on pip but is broken\n# Please AVOID installing via pip till we fix that\n\n# creating a new virtual environment\n$ python3 -m venv &lt;name-env&gt;\n# activate the virtual environment environment\n$ source &lt;/location-of-virt-env/name-env/bin/activate&gt;\n# install package into virtual environment\n$ pip install pyshbundle\n\n# clone the repository in order to access the notebooks and data\n$ git clone https://github.com/GESS-research-group/pyshbundle.git\n</code></pre> For more details refer to the installation section.</p>"},{"location":"#group","title":"Group","text":"<p>Geodesy for Earth system science (GESS) research Group at ICWaR, IISc</p>"},{"location":"#credits-for-the-theme","title":"Credits for the theme","text":"<p>This package was created with Cookiecutter and the giswqs/pypackage project template.</p>"},{"location":"acknowledgement/","title":"Acknowledgement:","text":"<p>The authors would like to thank Dr.-Ing. Markus Antoni and Clara Buetzler, Institute of Geodesy, University of Stuttgart, Germany, for early feedback. We are grateful for the financial support from IISc-ISRO Space Technology Cell for funding the project titled \"Improving the spatial resolution of GRACE TWS for India using remote sensing datasets and modeling approach\" under grant number STC0437. BDV would like to acknowledge the financial support from Science and Engineering Research Board, Government of India, under the grand agreement number SRG/2022/000625 for the MATRA project.</p> <p>Please note that PySHbundle has adapted the following code packages, both licensed under GNU General Public License</p> <ol> <li> <p>SHbundle: https://www.gis.uni-stuttgart.de/en/research/downloads/shbundle/</p> </li> <li> <p>Downscaling GRACE Total Water Storage Change using Partial Least Squares Regression - https://springernature.figshare.com/collections/Downscaling_GRACE_Total_Water_Storage_Change_using_Partial_Least_Squares_Regression/5054564 </p> </li> </ol>"},{"location":"acknowledgement/#key-papers-referred","title":"Key Papers Referred:","text":"<ol> <li> <p>Vishwakarma, B. D., Horwath, M., Devaraju, B., Groh, A., &amp; Sneeuw, N. (2017).        A data\u2010driven approach for repairing the hydrological catchment signal damage        due to filtering of GRACE products. Water Resources Research,        53(11), 9824-9844. https://doi.org/10.1002/2017WR021150</p> </li> <li> <p>Vishwakarma, B. D., Zhang, J., &amp; Sneeuw, N. (2021).        Downscaling GRACE total water storage change using        partial least squares regression. Scientific data, 8(1), 95.       https://doi.org/10.1038/s41597-021-00862-6</p> </li> </ol>"},{"location":"auxillary_codes/","title":"Auxillary Codes","text":"<p>The helper functions of the core functions are under the <code>shutils</code> script.  See Core Functionality.</p>"},{"location":"auxillary_codes/#pyshbundle.shutils.Gaussian","title":"<code>Gaussian(L, cap)</code>","text":"<p>Generates values for a Gaussian smoothing filter.</p> <p>The program delivers the spherical harmonic coefficients of a Gaussian smoothing filter. The coefficients are calculated according to Wahr et al. (1998) equation (34) and Swenson and Wahr equation (34).</p> <p>Parameters:</p> Name Type Description Default <code>L</code> <code>int</code> <p>Maximum degree of the spherical harmonics.</p> required <code>cap</code> <code>int</code> <p>Half width of Gaussian smoothing function [km].</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Smoothing coefficients of the Gausiann filter.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>L</code> is not an integer.</p> <code>ValueError</code> <p>If <code>L</code> is less than or equal to 2.</p> <code>TypeError</code> <p>If <code>cap</code> is not an integer.</p> References <p>Wahr et al. (1998) equation (34) and Swenson and Wahr equation (34).</p> Author <p>Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def Gaussian(L: int, cap: int):\n    \"\"\"Generates values for a Gaussian smoothing filter.\n\n    The program delivers the spherical harmonic coefficients of a Gaussian\n    smoothing filter. The coefficients are calculated according to Wahr et al. (1998)\n    equation (34) and Swenson and Wahr equation (34).\n\n    Args:\n        L (int): Maximum degree of the spherical harmonics.\n        cap (int): Half width of Gaussian smoothing function [km].\n\n    Returns:\n        (np.ndarray): Smoothing coefficients of the Gausiann filter.\n\n    Raises:\n        TypeError: If `L` is not an integer.\n        ValueError: If `L` is less than or equal to 2.\n        TypeError: If `cap` is not an integer.\n\n    References:\n        Wahr et al. (1998) equation (34) and Swenson and Wahr equation (34).\n\n    Author:\n        Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).\n    \"\"\"\n\n    #Check input\n    if type(L) != int:\n        raise TypeError('Degree must be integer')\n\n    if L&lt;2:\n        raise ValueError('Maximum degree must be higher than 2')\n\n    if type(cap) != int:\n        raise TypeError('Cap size must be an integer')\n\n    #Calculations\n    W = np.zeros([L+1, 1])\n    b = np.log(2)/(1 - np.cos(cap/6371))\n\n    #Recursive calculation of the weighting coefficients\n    W[0,0] = 1\n    W[1,0] = np.power(10, np.log10( (1 + np.exp(-2*b))/(1-np.exp(-2*b)) - (1/b)))\n\n    i = 1\n    while i &lt; L:        \n        j = i + 1\n        W[i+1][0] = W[i-1][0] - (2*(j-1) + 1)/b * W[i][0]\n        if W[i+1, 0] &gt; W[i] or W[i+1] &lt; 0:\n            W[i+1] = 0\n        i = i + 1\n\n    return W\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.derivALF","title":"<code>derivALF(inn, miin, plin, m, lmax)</code>","text":"<p>Function to calculate the derivative of the associated Legendre functions.</p> <p>Parameters:</p> Name Type Description Default <code>inn</code> <code>ndarray</code> <p>Input array representing the initial condition.</p> required <code>miin</code> <code>ndarray</code> <p>Array for the preceding elements in the recursion.</p> required <code>plin</code> <code>ndarray</code> <p>Array for the subsequent elements in the recursion.</p> required <code>m</code> <code>int</code> <p>Order of the associated Legendre functions.</p> required <code>lmax</code> <code>int</code> <p>Maximum degree.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Derivatives of the associated Legendre functions.</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def derivALF(inn, miin, plin, m, lmax):\n    \"\"\"\n    Function to calculate the derivative of the associated Legendre functions.\n\n    Args:\n        inn (np.ndarray): Input array representing the initial condition.\n        miin (np.ndarray): Array for the preceding elements in the recursion.\n        plin (np.ndarray): Array for the subsequent elements in the recursion.\n        m (int): Order of the associated Legendre functions.\n        lmax (int): Maximum degree.\n\n    Returns:\n        (numpy.ndarray): Derivatives of the associated Legendre functions.\n    \"\"\"\n    l = np.arange(m,lmax+2,1)\n    if m == 0:\n        inn[:,0] = 0\n        if lmax &gt; m:             \n            inn[:,1:] = plin*(-np.sqrt(    ((l[1:]+1)*l[1:]   /2).real))            # (-ones(n,1)*realsqrt((l(2:end)+1).*l(2:end)./2)).*plin            \n    elif m == 1:\n        inn[:,0] = miin[:,1]\n        if lmax &gt; m: \n            inn[:,1:] =  miin[:,2:]*(np.sqrt((l[1:]+1)*l[1:]/2).real) -0.5*plin*(np.sqrt((l[1:]-1)*(l[1:]+2)).real)\n    elif m == lmax:\n        inn[:,0] = np.sqrt(m/2*miin[:,1:]).real\n    else:\n        inn[:,0] = np.sqrt((m/2)*miin[:,1:]).real\n        if lmax &gt; m: \n            inn[:,1:] = 0.5*miin[:,2:]*np.sqrt((l[:,1:]+m)*(l[:,1:]-m+1)).real - 0.5*plin*(np.sqrt((l[:,1:]-m)*(l[:,1:]+m+1)).real)\n    return inn\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.eigengrav","title":"<code>eigengrav(lmax, fstr, h)</code>","text":"<p>Returns the isotropic spectral transfer (or: eigenvalues) of several gravity related quantities.  Upward continuation may be included.</p> <p>Parameters:</p> Name Type Description Default <code>lmax</code> <code>int</code> <p>Maximum degree of Spherical Coefficients.</p> required <code>fstr</code> <code>str</code> <p>Denoting the functional under consideration: 'none',  'geoid', 'dg', 'gravity' ... gravity anomaly, 'potential',  'tr' .............. gravity disturbance,  'trr' ............. (d^2/dr^2) 'slope' ........... size of surface gradient,  'water' ........... equivalent water thickness,  'smd' ............. surface mass density. 'height' .......... vertical displacements.</p> required <code>h</code> <code>float</code> <p>Height above Earth mean radius [m].</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Transfer matrix. Size and shape equal to lmax.          Units are respectively [none], [m], [mGal], [mGal], [E], [m^2/s^2], [rad], [m], kg/m^2</p> Uses <p>upwcon, lovenr, uberall/constants, uberall/isint</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>Enter a valid lmax value.</p> Author <p>Dr. Bramha Dutt Vishwakarma, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def eigengrav(lmax: int, fstr: str, h: float):\n    \"\"\"\n    Returns the isotropic spectral transfer (or: eigenvalues) of several gravity related quantities. \n    Upward continuation may be included.\n\n    Args:\n        lmax (int): Maximum degree of Spherical Coefficients.\n        fstr (str): Denoting the functional under consideration:\n            'none', \n            'geoid',\n            'dg', 'gravity' ... gravity anomaly,\n            'potential', \n            'tr' .............. gravity disturbance, \n            'trr' ............. (d^2/dr^2)\n            'slope' ........... size of surface gradient, \n            'water' ........... equivalent water thickness, \n            'smd' ............. surface mass density.\n            'height' .......... vertical displacements.\n        h (float): Height above Earth mean radius [m].\n\n    Returns:\n        (np.ndarray): Transfer matrix. Size and shape equal to lmax. \n                    Units are respectively [none], [m], [mGal], [mGal], [E], [m^2/s^2], [rad], [m], [kg/m^2] [n x 1]\n\n    Uses:\n        upwcon, lovenr, uberall/constants, uberall/isint\n\n    Raises:\n        TypeError: Enter a valid lmax value.\n\n    Author:\n        Dr. Bramha Dutt Vishwakarma, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).\n    \"\"\"\n\n    if type(lmax) == int:\n        rows = 1\n    else:\n        rows = len(lmax)\n    # rows = len(l)\n\n    if rows &gt; 1 or lmax &lt; 0:\n        raise TypeError(\"Enter a valid lmax value\")\n\n    r = GC.ae + h\n\n    # lmax issue - using lmax as per used in shbundle\n    # no reference for height\n\n    if fstr == 'none':\n        tf = np.ones((1, lmax+1))\n    elif fstr == 'geoid':\n        tf = np.ones((1, lmax+1)) * r\n    elif fstr == 'potential':\n        tf = np.ones((1, lmax+1)) * (GC.GM/r)\n    elif fstr == 'gravity' or fstr == 'dg':\n        tf = np.multiply(range(-1, lmax, 1), ((GC.GM/r/r) * 1e5))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'tr':\n        tf = np.multiply(range(-1, -(lmax+2), -1), ((GC.GM/r/r) * 1e5))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'trr':\n        tf = np.multiply(range(1, (lmax+2), 1),\n                            range(2, (lmax + 3), 1))*((GC.GM/r/r) * 1e9)\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'slope':\n        tf = np.sqrt(np.multiply(\n            range(0, lmax+1, 1), range(1, lmax+2, 1)))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'water':\n        ln = GB.lovenr(lmax)\n        tf = np.divide(np.multiply(\n            5.517*r, np.add(range(0, 2*lmax + 1, 2), 1)), np.multiply(3, (1+ln)))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'smd':\n        ln = GB.lovenr(lmax)\n        tf = np.divide(np.multiply(\n            5517*r, np.add(range(0, 2*lmax + 1, 2), 1)), np.multiply(3, (1+ln)))\n        tf = tf.reshape((1, lmax+1))\n    elif fstr == 'height':\n        kl, hl, ll = GB.lovenrPREM(90, 'CF')\n        tf = np.divide(np.multiply(hl, (GC.ae*1000)), np.add(kl, 1))\n    else:\n        ValueError('Requested functional FSTR not available.')\n\n    if h &gt; 0:\n        upConTerm = GB.upwcon(lmax, h)\n        tf = np.multiply(tf, upConTerm)\n\n    return(tf)\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.grule","title":"<code>grule(n)</code>","text":"<p>Computes Gauss base points and weight factors using the algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of base points required.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing: - bp (numpy.ndarray): Cosine of the base points. - wf (numpy.ndarray): Weight factors for computing integrals and such.</p> References <ul> <li>'Methods of Numerical Integration' by Davis and Rabinowitz, page 365, Academic Press, 1975.</li> </ul> Author <p>Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def grule(n: int):\n    \"\"\"\n    Computes Gauss base points and weight factors using the algorithm.\n\n    Args:\n        n (int): Number of base points required.\n\n    Returns:\n        tuple: A tuple containing:\n            - bp (numpy.ndarray): Cosine of the base points.\n            - wf (numpy.ndarray): Weight factors for computing integrals and such.\n\n    References:\n        - 'Methods of Numerical Integration' by Davis and Rabinowitz, page 365, Academic Press, 1975.\n\n    Author:\n        Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n    \"\"\"\n    bp = np.zeros((n,1))\n    wf = bp\n    iter = 2\n    m = np.floor((n+1)/2)\n    e1 = n * (n+1)\n\n\n    mm = 4*m - 1\n    t = (np.pi / (4*n + 2)) * np.arange(3,mm+4,4)\n    nn = (1 - (1 - 1/n)/(8*n*n))\n    x0 = nn * np.cos(t)\n\n\n    for i in range(iter):\n        pkm1 = 1\n        pk = x0\n\n        for kk in range(n-1):\n            k = kk + 2\n            t1 = x0 * pk\n            pkp1 = t1 - pkm1 - (t1-pkm1)/k  + t1\n            pkm1=pk\n            pk=pkp1\n\n        den = 1 - x0*x0\n        d1 = n * (pkm1 - x0*pk)\n        dpn = d1/den\n\n\n        d2pn = (2*x0*dpn - e1*pk) / den\n        d3pn = (4*x0*d2pn + (2-e1)*dpn)/den\n        d4pn = (6*x0*d3pn + (6-e1)*d2pn)/den\n        u = pk/dpn\n        v = d2pn/dpn\n        h = -u * (1+(.5*u)*(v+u*(v*v - u*d3pn/(3*dpn))))\n        p = pk + h*(dpn+(0.5*h)*(d2pn+(h/3)*(d3pn + 0.25*h*d4pn)))\n        dp = dpn + h*(d2pn+(0.5*h)*(d3pn+h*d4pn/3))\n        h = h-p/dp\n        x0 = x0+h\n\n    bp = -x0-h\n    fx = d1 - h*e1*(pk+(h/2)*(dpn+(h/3)*(d2pn+(h/4)*(d3pn+(0.2*h)*d4pn))))\n    wf = [2 * (1 - np.power(bp,2))]/(fx*fx)\n\n\n    for i in range(len(bp),n):\n        bp = np.append(bp,[0])\n        wf = np.append(wf,[0])\n\n    if ((m)+(m)) != (n):\n        m = m-1\n\n    for i in range(1,int(m+1)):\n        bp[-i] = -bp[i-1]\n        wf[-i] = wf[i-1] \n    return bp, wf\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.iplm","title":"<code>iplm(l, m, theRAD, dt=-9999)</code>","text":"<p>Integrals of the fully normalized associated Legendre functions over blocks for a selected order M.</p> <p>Parameters:</p> Name Type Description Default <code>l</code> <code>array</code> <p>Degree (vector). Integer, but not necessarily monotonic. For l &lt; m a vector of zeros will be returned.</p> required <code>m</code> <code>int</code> <p>Order of the Legendre function. If absent, m = 0 is assumed.</p> required <code>theRAD</code> <code>array</code> <p>Co-latitude in radians.</p> required <code>dt</code> <code>int</code> <p>Integration block-size [rad] (scalar). Defaults to -9999.</p> <code>-9999</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Matrix with integrated Legendre functions. Functions are integrated from theRAD(i)-dt/2 till theRAD(i)+dt/2. The matrix has length(TH) rows and length(L) columns, unless L  or TH is scalar. Then the output vector follows the shape of  respectively L or TH.</p> Notes <p>The blocks at the pole might become too large under circumstances. This is not treated separately, i.e. unwanted output may appear. In case TH is scalar, dt will be 1 (arbitrarily).</p> Uses <p><code>plm</code></p> Author <p>Vivek Kumar Yadav, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def iplm(l, m:int, theRAD, dt=-9999):\n    \"\"\"\n    Integrals of the fully normalized associated Legendre functions over blocks for a selected order M.\n\n    Args:\n        l (numpy.array): Degree (vector). Integer, but not necessarily monotonic.\n            For l &lt; m a vector of zeros will be returned.\n        m (int): Order of the Legendre function. If absent, m = 0 is assumed.\n        theRAD (numpy.array): Co-latitude in radians.\n        dt (int, optional): Integration block-size [rad] (scalar). Defaults to -9999.\n\n    Returns:\n        (numpy.ndarray): Matrix with integrated Legendre functions.\n            Functions are integrated from theRAD(i)-dt/2 till theRAD(i)+dt/2.\n            The matrix has length(TH) rows and length(L) columns, unless L \n            or TH is scalar. Then the output vector follows the shape of \n            respectively L or TH.\n\n    Notes:\n        The blocks at the pole might become too large under circumstances.\n        This is not treated separately, i.e. unwanted output may appear.\n        In case TH is scalar, dt will be 1 (arbitrarily).\n\n    Uses:\n        `plm`\n\n    Author:\n        Vivek Kumar Yadav, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n    \"\"\"\n\n    if dt == -9999:\n        dt = np.pi / 180 if len(theRAD) == 1 else theRAD[1] - theRAD[0]\n\n    if min(l.shape) != 1:\n        raise ValueError('Degree l must be a vector (or scalar)')\n\n    if not np.all(np.remainder(l, 1) == 0):\n        raise ValueError('Vector l contains non-integers !!')\n\n    if not np.remainder(m, 1) == 0:\n        raise ValueError('Order must be integer')\n\n    if dt == 0:\n        raise ValueError('DT cannot be zero')\n\n\n    lcol = len(l)\n    trow = len(theRAD)\n    n = len(theRAD)\n    theRAD.T\n    if min(theRAD) &lt; 0 or max(theRAD) &gt; np.pi:\n        raise ValueError('Is the co-latitude ''theta'' given in radian?')\n\n    lmax = max(l[0])\n    mfix = m\n    lvec = np.transpose(l) \n    l = np.arange(mfix,lmax+1,1)\n\n    # Initialization of cosine, sine and Plm functions\n    stplus  = np.sin(theRAD+dt/2)\n    stmin   = np.sin(theRAD-dt/2)\n    ctplus  = np.cos(theRAD+dt/2)\n    ctmin   = np.cos(theRAD-dt/2)\n    plmplus = np.ones([n,lmax+1])\n    plmmin = np.ones([n,lmax + 1])\n    plmplus[:,l] = plm(np.array([l]),mfix,(theRAD + dt/2),3,1)[:,:,0]                  # Tesserals\n    plmmin[:,l] = plm(np.array([l]),mfix,(theRAD - dt/2),3,1)[:,:,0] \n    if mfix &gt; 0:\n        m = np.arange(1,mfix + 1,1)\n        mm = 2*m\n        fac = np.sqrt(2*np.cumprod((mm+1)/mm))\n        mgr, stp = np.meshgrid(m, stplus)\n        fgr, stm = np.meshgrid(fac, stmin)\n        plmplus[:, m] = fgr * np.power(stp, mgr)\n        plmmin[:, m] = fgr * np.power(stm, mgr)\n    ptmp = np.zeros([n, lmax +2 ])\n    ptmp00 = np.cos(theRAD - dt/2) - ctplus\n    ptmp11 = np.sqrt(3)/2 * (dt - ctplus* stplus + ctmin* stmin)\n    ptmp10 = np.sqrt(3)/2 * (np.power(stplus,2) - np.power(stmin,2))\n    ptmp[:,0] = ptmp00\n\n    # Compute first the integrals of order m == 0\n    if mfix == 0:\n        ptmp[:,1] = ptmp10\n        for l in range(2,lmax+1,1):              #loop over the degree l \n            rootnm = np.sqrt( (2*l+1)*(2*l-1)/np.power(l,2))\n            root1nm = np.sqrt( (2*l-1)*(2*l-3)/np.power(l-1,2))\n            ptmp[:,l] = rootnm/(l+1)*(((l-2)*ptmp[:,l-2]/root1nm).T + np.power(stplus,2)*plmplus[:,l-1].T - np.power(stmin,2)*plmmin[:,l-1].T )\n    else:\n        # Compute the integrals of order m &gt; 0\n\n        # First we compute the diagonal element IPmm (lmax == mfix)\n\n        ptmp[:,1] = ptmp11\n        for l in range(2,mfix+1,1):\n            # print(l)\n            rootmm = np.sqrt( (2*l+1)/(2*l) )\n            root1mm = np.sqrt( (2*l-1)/(2*l-2))\n            if l == 2:\n                root1mm = np.sqrt(3)\n\n            ptmp[:,l] = rootmm/(l+1)*( l*root1mm*ptmp[:,l-2].T - (ctplus*plmplus[:,l].T -ctmin*plmmin[:,l].T)/rootmm )\n    #the arbitrary element IPlm ( computed only when lmax &gt; mfix)        \n        if lmax &gt; mfix:\n            l = mfix + 1\n        #first we do the element IPlm, for which l - m = 1    \n            rootnm = np.sqrt( (2*l+1)*(2*l-1)/(l+mfix)/(l-mfix))\n            ptmp[:,l] = rootnm/(l+1)*(np.power(stplus,2)*plmplus[:,l-1].T - np.power(stmin,2)*plmmin[:,l-1].T)\n        #now we do the rest\n            for l in range(mfix+2,lmax+1,1):              #loop over the degree l\n                rootnm = np.sqrt( (2*l+1) * (2*l-1) / (l+mfix) / (l-mfix) )\n                root1nm = np.sqrt( (2*l-1) * (2*l-3) / (l-1+mfix) / (l-1-mfix) )\n                ptmp[:,l] = rootnm/(l+1)*( (l-2)*ptmp[:,l-2].T/root1nm + np.power(stplus,2)*plmplus[:,l-1].T -np.power(stmin,2)*plmmin[:,l-1].T)\n\n# --------------------------------------------------------------------\n        # The integrated functions have been computed. What remains to be done, is to\n        # extract the proper columns from ptmp, corresponding to the vector lvec. \n        # If l or theta is scalar the output matrix p reduces to a vector. It should\n        # have the shape of respectively theta or l in that case.\n# --------------------------------------------------------------------\n\n# p     = zeros(n, length(lvec))\n    lind = np.argwhere(lvec&lt;mfix)[:,0]      #index into l &lt; m\n    pcol = lvec + 1                         #index into columns of ptmp\n    pcol[lind] = (lmax + 2)*np.ones([len(lind),1])   #Now l &lt; m points to last col\n    p = ptmp[:,pcol[:,0]-1]                 #proper column extraction \n\n    if max(lvec.shape) == 1 and min(np.array([theRAD]).shape) == 1 and trow == 1:\n        p = p.T\n    if max(np.array([theRAD]).shape) == 1 and min(lvec.shape) == 1 and lcol == 1:\n        p = p.T\n    return p\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.ispec","title":"<code>ispec(a, b=-9999)</code>","text":"<p>Returns the function F from the spectra A and B.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>ndarray</code> <p>Cosine coefficients.</p> required <code>b</code> <code>ndarray</code> <p>Sine coefficients. Defaults to -9999.</p> <code>-9999</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The function F computed from the spectra A and B.</p> See Also <p><code>spec</code></p> Author <p>Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def ispec(a,b = -9999):\n    \"\"\"\n    Returns the function F from the spectra A and B.\n\n    Args:\n        a (numpy.ndarray): Cosine coefficients.\n        b (numpy.ndarray, optional): Sine coefficients. Defaults to -9999.\n\n    Returns:\n        (numpy.ndarray): The function F computed from the spectra A and B.\n\n    See Also:\n        `spec`\n\n    Author:\n        Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).\n    \"\"\"\n\n    n2 = a.shape[0]\n    a[0,:] = a[0, :]*2\n\n\n    if (np.absolute(b[n2-1,:]) &lt; 1e-10).all():\n        n = 2 * n2 - 2     \n        a[n2-1,:] = a[n2-1,:] * 2            \n        fs = (a - 1j * b)/2\n        fs  = (np.concatenate((fs,np.conj(fs[np.arange(n2-2,0,-1),:])), axis = 0))*max(n,1)\n\n    else:\n        n = 2 * n2 - 1                        \n        fs = (a - 1j * b)/2\n        fs = (np.concatenate((fs,np.conj(fs[np.arange(n2-1,0,-1),:])), axis = 0))*n\n\n    f = np.real(ifft(fs.T).T)\n    return f\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.lrecur","title":"<code>lrecur(inn, x, m, lmax)</code>","text":"<p>Helper function for recursion.</p> <p>Parameters:</p> Name Type Description Default <code>inn</code> <code>int</code> <p>Input value representing the initial condition.</p> required <code>x</code> <code>int</code> <p>The current value for the recursion.</p> required <code>m</code> <code>int</code> <p>Order of the recursion.</p> required <code>lmax</code> <code>int</code> <p>Maximum value for recursion.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Updated value after performing the recursion based on parameters.</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def lrecur(inn, x, m, lmax):\n    \"\"\"\n    Helper function for recursion.\n\n    Args:\n        inn (int): Input value representing the initial condition.\n        x (int): The current value for the recursion.\n        m (int): Order of the recursion.\n        lmax (int): Maximum value for recursion.\n\n    Returns:\n        (int): Updated value after performing the recursion based on parameters.\n    \"\"\"\n    for ll in np.arange(int(m)+1,lmax+1,1):\n       col   = ll - m+1\t\t\t                                                # points to the next collumn of ptmp\n       root1 = np.sqrt( (2*ll+1)*(2*ll-1)/((ll-m)*(ll+m)) ).real \n       root2 = np.sqrt( (2*ll+1)*(ll+m-1)*(ll-m-1) / ( (2*ll-3)*(ll-m)*(ll+m) ) ).real\n\n       # % recursion \n       if ll == m+1:\n           inn[:, col-1] = root1 *x*inn[:, col-2]\n       else:\n           inn[:, col-1] = root1 *x*inn[:, col-2] - root2 *inn[:, col-3] \n    return inn\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.naninterp","title":"<code>naninterp(X)</code>","text":"<p>This function uses cubic interpolation to replace NaNs.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>array</code> <p>Array with NaN values.</p> required <p>Returns:</p> Type Description <p>numpy.array: Cubic interpolated array.</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def naninterp(X):\n    \"\"\"\n    This function uses cubic interpolation to replace NaNs.\n\n    Args:\n        X (numpy.array): Array with NaN values.\n\n    Returns:\n        numpy.array: Cubic interpolated array.\n    \"\"\"\n\n    ok = ~np.isnan(X)\n    xp = ok.ravel().nonzero()[0] #Indices of xs with values\n    fp = X[~np.isnan(X)]\n\n    x  = np.isnan(X).ravel().nonzero()[0] #Indices of xs without values\n\n    pchip = PchipInterpolator(xp,fp) #Initialize scipy PHCIP cubic interpolation\n    X[np.isnan(X)] = pchip(x) #Interpolate Nan values in X\n\n    return X\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.neumann","title":"<code>neumann(inn)</code>","text":"<p>Returns the weights and nodes for Neumann's numerical integration.</p> <p>Parameters:</p> Name Type Description Default <code>inn</code> <code>int or array</code> <p>Base points (nodes) in the interval [-1;1].</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing: - w (numpy.array): Quadrature weights. - x (numpy.array): Base points (nodes) in the interval [-1;1].</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the input argument is not an integer.</p> <code>ValueError</code> <p>If there is an error in input dimensions.</p> Remarks <ul> <li>1st N.-method: see Sneeuw (1994) GJI 118, pp 707-716, eq. 19.5.</li> <li>2nd N.-method: see uberall/GRULE.</li> </ul> Todo <ul> <li>TypeError is more relevant and shape error from numpy.</li> </ul> Uses <p><code>grule</code>, <code>plm</code>.</p> Author <p>Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def neumann(inn):\n    \"\"\"\n    Returns the weights and nodes for Neumann's numerical integration.\n\n    Args:\n        inn (int or numpy.array): Base points (nodes) in the interval [-1;1].\n\n    Returns:\n        tuple: A tuple containing:\n            - w (numpy.array): Quadrature weights.\n            - x (numpy.array): Base points (nodes) in the interval [-1;1].\n\n    Raises:\n        TypeError: If the input argument is not an integer.\n        ValueError: If there is an error in input dimensions.\n\n    Remarks:\n        * 1st N.-method: see Sneeuw (1994) GJI 118, pp 707-716, eq. 19.5.\n        * 2nd N.-method: see uberall/GRULE.\n\n    Todo:\n        + TypeError is more relevant and shape error from numpy.\n\n    Uses:\n        `grule`, `plm`.\n\n    Author:\n        Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).\n    \"\"\"\n\n    try: #if input is an integer\n        x, w = grule(inn)\n    except: #if input is an array\n        if(len(inn)==1): #2nd Neumann method\n            x, w = grule(inn)\n            if(np.not_equal(np.mod(x, 1), 0)): #Not integer\n                raise TypeError(\"Integer input argument required\")\n\n\n\n        elif min(inn.shape) == 1: #1st Neumann method #Size gives 2 outputs for 2d array in matlab; for row and column\n            x = inn\n            theRAD = np.arccos(x) #x in radian\n            l = np.array(list(range(len(x))))\n            pp = plm(l, theRAD)\n\n            rr = list([2])\n            for i in len(x-1):\n                rr.append(0)\n            r = np.asarray(rr)\n\n            w,resid,rank,s = np.linalg.lstsq(pp,r) #Solve system of equations; Double check this operation\n            if(x.shape != w.shape):\n                w = w.T\n\n        else:\n            raise ValueError(\"Error in input dimensions\")\n            # TO DO: Write more descriptive exception messages\n\n    return w, x\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.normalklm","title":"<code>normalklm(lmax, typ='wgs84')</code>","text":"<p>Returns an ellipsoidal normal field consisting of normalized -Jn, n=0,2,4,6,8.</p> <p>Parameters:</p> Name Type Description Default <code>lmax</code> <code>int</code> <p>Maximum degree of the spherical harmonics.</p> required <code>typ</code> <code>str</code> <p>Ellipsoids can be either 'wgs84' (World Geodetic System 84),                   'grs80', or 'he' (hydrostatic equilibrium ellipsoid).</p> <code>'wgs84'</code> <p>Returns:</p> Type Description <code>array</code> <p>Normal field in CS-format (sparse array - [1, -J2, -J4, -J6, -J8]).</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If <code>lmax</code> is not an integer.</p> <code>ValueError</code> <p>If <code>lmax</code> is not positive.</p> <code>ValueError</code> <p>If <code>typ</code> is an unknown ellipsoid type. Supports 'wgs84', 'grs80', and 'he'.</p> References <ol> <li>J2, J4 values for hydrostatic equilibrium ellipsoid from Lambeck (1988)    \"Geophysical Geodesy\", p.18.</li> </ol> Author <p>Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def normalklm(lmax: int, typ: str = 'wgs84'):\n    \"\"\"\n    Returns an ellipsoidal normal field consisting of normalized -Jn, n=0,2,4,6,8.\n\n    Args:\n        lmax (int): Maximum degree of the spherical harmonics.\n        typ (str, optional): Ellipsoids can be either 'wgs84' (World Geodetic System 84), \n                             'grs80', or 'he' (hydrostatic equilibrium ellipsoid).\n\n    Returns:\n        (numpy.array): Normal field in CS-format (sparse array - [1, -J2, -J4, -J6, -J8]).\n\n    Raises:\n        TypeError: If `lmax` is not an integer.\n        ValueError: If `lmax` is not positive.\n        ValueError: If `typ` is an unknown ellipsoid type. Supports 'wgs84', 'grs80', and 'he'.\n\n    References:\n        1. J2, J4 values for hydrostatic equilibrium ellipsoid from Lambeck (1988)\n           \"Geophysical Geodesy\", p.18.\n\n    Author:\n        Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).\n    \"\"\"\n\n    if type(lmax) != int:\n        raise TypeError(\"lmax should be integer\")\n\n    if lmax &lt; 0:\n        raise ValueError(\"lmax should be positive\")\n\n\n    typ_ = typ.lower()\n    if (typ_ == 'wgs84'):\n        J2     =  1.08262982131e-3     #% earth's dyn. form factor (= -C20 unnormalized)\n        J4     = -2.37091120053e-6    #% -C40 unnormalized\n        J6     =  6.08346498882e-9     #% -C60 unnormalized\n        J8     = -1.42681087920e-11    #% -C80 unnormalized\n        jcoefs = np.array([1, -J2, -J4, -J6, -J8]).T.reshape(5,1)\n        # as lmax + 2 is requires \n        l      = np.arange(0,min(lmax + 2,8 + 2), 2).T\n        l.reshape(l.shape[0],1)\n\n    elif (typ_ == 'grs80'):\n        J2     =  1.08263e-3         # % earth's dyn. form factor (= -C20 unnormalized)\n        J4     = -2.37091222e-6     #% -C40 unnormalized\n        J6     =  6.08347e-9        #% -C60 unnormalized\n        J8     = -1.427e-11         #% -C80 unnormalized\n        jcoefs = np.array([1, -J2, -J4, -J6, -J8]).reshape(5,1)\n        l      = np.arange(0,min(lmax + 2,8 + 2), 2).T\n        l.reshape(l.shape[0],1)\n\n    elif ((typ_ == 'he') or (typ_ == 'hydro')):\n        J2     = 1.072618e-3\t\t#% earth's dyn. form factor (= -C20 unnormalized)\n        J4     = 0.2992e-5     \t#% -C40 unnormalized\n        jcoefs = np.array([1, -J2, -J4]).T.reshape(5,1)\n        # adding (2) beacuse of arange function is only uptp last integer and not including last\n        l      = np.arange(0,min(lmax + 2,4 + 2), 2).T\n        l.reshape(l.shape[0],1)\n\n    else:\n        raise ValueError(\"Unknown type of ellipsoid:   \", typ)\n\n    coefs = jcoefs[:len(l)].T / np.sqrt(2*l + 1)\n#    coefs.reshape(coefs.shape[0],1)\n\n\n    data = np.array(coefs)[0]\n    row = np.array(l)\n    col = np.zeros(len(l))\n    # lmax = 96 then shape=(97, 97) -&gt; consisitent with everything else\n    nklm = sparse.coo_matrix((data,(row,col)),shape=(lmax+1,lmax+1)).toarray()\n    return nklm\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.plm","title":"<code>plm(l, m, thetaRAD, nargin, nargout)</code>","text":"<p>Fully normalized associated Legendre functions for a selected order M.</p> <p>Parameters:</p> Name Type Description Default <code>l</code> <code>array</code> <p>Degree, but not necessarily monotonic. For l &lt; m a vector of zeros will be returned.</p> required <code>m</code> <code>int</code> <p>Order. If absent, m = 0 is assumed.</p> required <code>thetaRAD</code> <code>array</code> <p>Co-latitude in radians.</p> required <code>nargin</code> <code>int</code> <p>Number of input arguments.</p> required <code>nargout</code> <code>int</code> <p>Number of output arguments.</p> required <p>Returns:</p> Type Description <code>array</code> <p>Fully normalized Legendre functions.</p> <code>array</code> <p>First derivative of the Legendre functions.</p> <code>array</code> <p>Second derivative of the Legendre functions.</p> Author <p>Vivek Kumar Yadav, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def plm(l: np.array, m:int, thetaRAD, nargin, nargout): \n    \"\"\"\n    Fully normalized associated Legendre functions for a selected order M.\n\n    Args:\n        l (numpy.array): Degree, but not necessarily monotonic. For l &lt; m a vector of zeros will be returned.\n        m (int): Order. If absent, m = 0 is assumed.\n        thetaRAD (numpy.array): Co-latitude in radians.\n        nargin (int): Number of input arguments.\n        nargout (int): Number of output arguments.\n\n    Returns:\n        (numpy.array): Fully normalized Legendre functions.\n        (numpy.array): First derivative of the Legendre functions.\n        (numpy.array): Second derivative of the Legendre functions.\n\n    Author:\n        Vivek Kumar Yadav, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc).\n    \"\"\"\n\n    if  min(l.shape) != 1:\n        raise ValueError('Degree l must be a vector (or scalar)') \n    if  np.remainder(l,1).all() != 0:\n        raise ValueError('Vector l contains non-integers !!') \n    if  np.remainder(m,1) != 0:\n        raise ValueError('Order must be integer')\n\n# PRELIMINARIES\n    lcol = len(l)\n    trow = len(thetaRAD)\n    lmax = int(max(l[0,:]))\n\n    if lmax &lt; m:\n        p = np.zeros([len(thetaRAD), len(l)], dtype='float')\n        dp = np.zeros([len(thetaRAD), len(l)], dtype='float')\n        ddp = np.zeros([len(thetaRAD), len(l)], dtype='float')\n        sys.exit([])\n\n    n = thetaRAD.size                                                               # number of latitudes\n    t = thetaRAD[:]\n    x = np.cos(t)\n    y = np.sin(t)\n    lvec = np.transpose(l)   \n    lvec = np.intc(lvec)                                                       # l can now be used as running index\n\n    if min(t).all() &lt; 0 and max(t).all() &gt; np.pi:\n        print('Warning: Is co-latitude in radians ?')\n\n    # Recursive computation of the temporary matrix ptmp, containing the Legendre\n    # functions in its columns, with progressing degree l. The last column of\n    # ptmp will contain zeros, which is useful for assignments when l &lt; m.\n    ptmp = np.zeros((n,lmax + 2 - m))\n    if nargout &gt;= 2:                                                                #  first derivative needs also P_{n,m+1} and P_{n,m-1}\n        ptmp_m1 = np.zeros((n,lmax + 3 - m), dtype='float')\n        ptmp_p1 = np.zeros((n,lmax + 1 -m), dtype='float')        \n        dptmp = np.zeros((n,lmax + 2 - m), dtype='float') \n    if nargout == 3:                                                                # second derivative needs also dP_{n,m+1} and dP_{n,m-1}\n        dptmp_m1 = np.zeros((n,lmax + 3 -m), dtype='float')\n        dptmp_p1 = np.zeros((n,lmax + 1 -m), dtype='float')\n        ptmp_m2 = np.zeros((n,lmax + 4 -m), dtype='float')                                         # but these first derivative need dP_{n,m+2} and dP_{n,m-2}\n        ptmp_p2 = np.zeros((n,lmax - m), dtype='float')\n        ddptmp = np.zeros((n,lmax + 2 -m), dtype='float')\n\n    # sectorial recursion: PM (non-recursive, though)\n    ptmp[:,0] = secrecur(m,y)\n    if nargout &gt;= 2:                                                                # frist derivative needs preceding and subsequent element\n        if m &gt; 0:    \n            ptmp_m1[:,0] = secrecur(m-1,y)                                          # preceding elements\n        if m &lt; lmax: \n            ptmp_p1[:,0] = secrecur(m+1,y)                                          # subsequent elemtens\n    if nargout == 3:                                                                # second derivative needs P_{n,m+2} and P_{n,m-2} as well\n        if m &gt; 1:           \n            ptmp_m2[:,0] = secrecur(m-2,y)                                          # preceding elements\n        if m &lt; lmax-1: \n            ptmp_p2[:,0] = secrecur(m+2,y)                                          # subsequent elemtens\n\n    # l-recursion: P\n    ptmp = lrecur(ptmp,x,m,lmax);\n    if nargout &gt;= 2:                                                                # frist derivative needs preceding and subsequent element\n        if m &gt; 0:\n            ptmp_m1 = lrecur(ptmp_m1,x,m-1,lmax)                                    # preceding elements\n        if m &lt; lmax:\n            ptmp_p1 = lrecur(ptmp_p1,x,m+1,lmax)                                    # subsequent elemtens\n\n    if nargout == 3:                                                                # second derivative needs P_{n,m+2} and P_{n,m-2} as well\n        if m &gt; 1:\n            ptmp_m2 = lrecur(ptmp_m2,x,m-2,lmax)                                    # preceding elements\n        if m &lt; lmax-1:\n            ptmp_p2 = lrecur(ptmp_p2,x,m+2,lmax)                                    # subsequent elemtens\n\n    # now compute the derivatives \n    if nargout &gt;= 2:                                                                # first derivative\n        dptmp = derivALF(dptmp,ptmp_m1,ptmp_p1,m,lmax)\n    if nargout == 3:                                                                # second derivative\n        if m &gt; 0:    \n            dptmp_m1 = derivALF(dptmp_m1,ptmp,ptmp_m2,m-1,lmax)\n        if m &lt; lmax:\n            dptmp_p1 = derivALF(dptmp_p1,ptmp,ptmp_p2,m+1,lmax)\n        ddptmp = derivALF(ddptmp,dptmp_m1,dptmp_p1,m,lmax)\n\n\n# --------------------------------------------------------------------\n        # The Legendre functions have been computed. What remains to be done, is to\n        # extract the proper columns from ptmp, corresponding to the vector lvec. \n        # If l or thetaRAD is scalar the output matrix p reduces to a vector. It should\n        # have the shape of respectively thetaRAD or l in that case.\n# --------------------------------------------------------------------\n    lind       = (lvec &lt; m)   \t # index into l &lt; m\n    pcol       = lvec - m + 0\t\t\t                                            # index into columns of ptmp\n    pcol[lind] = np.ndarray((lmax-m+2-6)*np.ones((sum(sum(lind)),1)))\t            # Now l &lt; m points to last col.\n    p      = ptmp[:,pcol]\t\t\t                                                # proper column extraction \n    if nargout &gt;= 2:\n        dp =  dptmp[:,pcol]                                                         # proper column extraction \n    if nargout == 3: \n        ddp = ddptmp[:,pcol]                                                        # proper column extraction  \n    if max(lvec.shape)==1  and min(thetaRAD.shape)==1 and (trow == 1):\n        p = p.T\n        if nargout &gt;= 2:\n            dp  = np.transpose(dp)\n        if nargout == 3:\n            ddp = np.transpose(ddp)\n    if max(thetaRAD.shape)==1 and min(lvec.shape)==1  and (lcol == 1):\n        p = p.T\n        if nargout &gt;= 2:\n            dp  = dp.T  \n        if nargout == 3:\n            ddp = ddp.T\n\n    if nargout == 1: \n        return p\n    if nargout == 2: \n        return p,dp\n    if nargout == 3: \n        return p, dp, ddp\n</code></pre>"},{"location":"auxillary_codes/#pyshbundle.shutils.secrecur","title":"<code>secrecur(m, y)</code>","text":"<p>Helper Function for sectorial recursion. This function computes the sectorial recursion for given parameters.</p> <p>Parameters:</p> Name Type Description Default <code>m</code> <code>int</code> <p>The order of the recursion.</p> required <code>y</code> <code>ndarray</code> <p>The input array for which the recursion is computed.</p> required <p>Returns:</p> Type Description <p>numpy.ndarray: The result of the sectorial recursion.</p> Source code in <code>pyshbundle/shutils.py</code> <pre><code>def secrecur(m, y):\n    \"\"\"\n    Helper Function for sectorial recursion.\n    This function computes the sectorial recursion for given parameters.\n\n    Args:\n        m (int): The order of the recursion.\n        y (numpy.ndarray): The input array for which the recursion is computed.\n\n    Returns:\n        numpy.ndarray: The result of the sectorial recursion.\n    \"\"\"\n    if m == 0:\n       fac = 1\n    else:\n       mm  = np.array([2*x for x in range(1, m+1)])\n       fac = np.sqrt(2*np.prod((mm+1)/mm))\n    out = fac*np.power(y,m)                                                         # The 1st column of ptmp\n    return out\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways.</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/GESS-research-group/pyshbundle/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#found-bugs","title":"Found Bugs!!!","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#want-new-functionality","title":"Want New Functionality?","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#lets-improve-documentation","title":"Let's Improve Documentation","text":"<p>pyshbundle could always use more documentation, whether as part of the official pyshbundle docs, in docstrings, or even on the web in blog posts, articles, and such.</p> <p>Another prefered way is to create explainatory tutorials. Using the <code>PySHBundle</code> functions to explain the <code>Spherical Harmonics</code> and <code>GRACE Data Processing</code>.</p>"},{"location":"contributing/#feedback","title":"Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/GESS-research-group/pyshbundle/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up pyshbundle for local development.</p> <ol> <li> <p>Fork the pyshbundle repo on GitHub.</p> </li> <li> <p>Setup a seperate development environment.     <pre><code># clone the repo and fetch the dev branch\n$ git clone git@github.com:mn5hk/pyshbundle.git\n\n# creating a new virtual environment\n$ python3 -m venv &lt;name-env&gt;\n\n# install the dependencies from the requirements-dev file\n$ pip install -r ../pyshbundle/requirements-dev.txt\n\n# activate the virtual environment environment\n$ source &lt;/location-of-virt-env/name-env/bin/activate&gt;\n</code></pre></p> </li> <li> <p>Build the latest repo in the development virtual environment.     <pre><code># install package into virtual environment\n$ pip install ../pyshbundle/dist/&lt;required-version&gt;.tar.gz\n\n# you also have the option to build the module using, be careful of \n$ python setup.py sdist\n</code></pre></p> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes lo    cally.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <p>TBD...</p>"},{"location":"convert_data_formats/","title":"Convert Data Formats","text":""},{"location":"convert_data_formats/#pyshbundle.reshape_SH_coefficients.cklm2sc_new","title":"<code>cklm2sc_new(clm_mat, lmax)</code>","text":"<p>Transforms the spherical harmonics coefficients data in clm or klm format into a SC matrix.</p> <p>Parameters:</p> Name Type Description Default <code>clm_mat</code> <code>ndarray</code> <p>The input matrix containing spherical harmonics coefficients.</p> required <code>lmax</code> <code>int</code> <p>The maximum degree of the spherical harmonic expansion.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing: - scmat (numpy.ndarray): The SC matrix. - dev_scmat (numpy.ndarray): The deviation SC matrix.</p> Source code in <code>pyshbundle/reshape_SH_coefficients.py</code> <pre><code>def cklm2sc_new(clm_mat, lmax: int):\n    \"\"\"\n    Transforms the spherical harmonics coefficients data in clm or klm format into a SC matrix.\n\n    Args:\n        clm_mat (numpy.ndarray): The input matrix containing spherical harmonics coefficients.\n        lmax (int): The maximum degree of the spherical harmonic expansion.\n\n    Returns:\n        tuple: A tuple containing:\n            - scmat (numpy.ndarray): The SC matrix.\n            - dev_scmat (numpy.ndarray): The deviation SC matrix.\n    \"\"\"\n\n    # initialise an empty sc matrix\n    sc_mat = np.zeros([lmax+1, 2*lmax + 1])\n    dev_sc_mat = np.zeros([lmax+1, 2*lmax + 1])\n\n    # navigating the maze of indices\n\n    # Use logical indices\n\n    # sc mat requires padding - Taken care of by the earlier initialisation\n    # \n    # filling the value at appropriate locaation is the key\n    # \n    # Approach-1\n        # run through rows(degree) and fill the cols(order) respectively\n\n    # Approach -2\n        # create a row_func s.t. [....., C22, C21, C20, S21, S22, .......]\n        # then stack the rows\n\n    # First flatten the SC matrix - column wise aka Fortran style\n    # get the flattented idx to be raplaced using sub2ind \n    # replace the indices at those locations using \n    # unflatten the matrix\n\n    shape_sc = sc_mat.shape\n\n    # following the approach similar to Octave implementation\n    # using matrix operations to improve the time efficiency as compared to looping\n    idx_s = sub2ind(sc_mat.shape, clm_mat[:, 0].astype('i'), (lmax - clm_mat[:, 1]).astype('i')).astype('i')\n    idx_c = sub2ind(sc_mat.shape, clm_mat[:, 0].astype('i'), (lmax + clm_mat[:, 1]).astype('i')).astype('i')\n\n\n    flat_sc = sc_mat.flatten(\"F\")\n    # Attention first place the slm coeff. or else it will relace zonal clm coeff.\n    flat_sc[idx_s] = clm_mat[:, 3]\n    flat_sc[idx_c] = clm_mat[:, 2]\n\n    flat_sc2 = dev_sc_mat.flatten(\"F\")\n    flat_sc2[idx_s] = clm_mat[:, 5]\n    flat_sc2[idx_c] = clm_mat[:, 4]\n\n    dev_scmat = flat_sc2.reshape(shape_sc)\n\n    scmat = flat_sc.reshape(shape_sc)\n\n    # with one flag include for \n\n    return scmat, dev_scmat\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.reshape_SH_coefficients.clm2cs","title":"<code>clm2cs(data_mat, lmax, sigma_flag=False)</code>","text":"<p>Converts the format from CLM to CS.</p> <p>Under the hood uses the <code>clm2sc</code> and <code>sc2cs</code> functions.</p> <p>Parameters:</p> Name Type Description Default <code>data_mat</code> <code>ndarray</code> <p>List containing [degree, order, clm, slm, delta clm, delta slm, start date, end date].</p> required <code>lmax</code> <code>int</code> <p>Max Degree of the spherical harmonic expansion.</p> required <code>sigma_flag</code> <code>bool</code> <p>Flag to return the standard deviation data in CS format or not. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Spherical Harmonic Coefficients in CS format.</p> Source code in <code>pyshbundle/reshape_SH_coefficients.py</code> <pre><code>def clm2cs(data_mat: np.ndarray, lmax: int, sigma_flag=False):\n    \"\"\"\n    Converts the format from CLM to CS.\n\n    Under the hood uses the `clm2sc` and `sc2cs` functions.\n\n    Args:\n        data_mat (numpy.ndarray): List containing [degree, order, clm, slm, delta clm, delta slm, start date, end date].\n        lmax (int): Max Degree of the spherical harmonic expansion.\n        sigma_flag (bool, optional): Flag to return the standard deviation data in CS format or not. Defaults to False.\n\n    Returns:\n        (numpy.ndarray): Spherical Harmonic Coefficients in CS format.\n    \"\"\"\n    if sigma_flag:\n        sc_mat, dev_sc = clm2sc(data_mat=data_mat, lmax=lmax, sigma_flag=True)\n        return sc2cs(sc_mat), sc2cs.sc2cs(dev_sc)\n    else:\n        sc_mat = clm2sc(data_mat=data_mat, lmax=lmax, sigma_flag=False)\n        return sc2cs(sc_mat)\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.reshape_SH_coefficients.clm2sc","title":"<code>clm2sc(data_mat, lmax, sigma_flag=False)</code>","text":"<p>Converts the spherical harmonic coefficients from CLM format to SC format.</p> <p>Parameters:</p> Name Type Description Default <code>data_mat</code> <code>ndarray</code> <p>List containing [degree, order, clm, slm, delta clm, delta slm, start date, end date].</p> required <code>lmax</code> <code>int</code> <p>Max Degree of the spherical harmonic expansion.</p> required <code>sigma_flag</code> <code>bool</code> <p>Flag to return the standard deviation data in CS format or not. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Spherical Harmonic Coefficients in SC format.</p> References <p>Refer to the SHBundle or PySHBundle docs for the different data storage and retrieval formats.</p> Source code in <code>pyshbundle/reshape_SH_coefficients.py</code> <pre><code>def clm2sc(data_mat: np.ndarray, lmax: int, sigma_flag=False):\n    \"\"\"\n    Converts the spherical harmonic coefficients from CLM format to SC format.\n\n    Args:\n        data_mat (numpy.ndarray): List containing [degree, order, clm, slm, delta clm, delta slm, start date, end date].\n        lmax (int): Max Degree of the spherical harmonic expansion.\n        sigma_flag (bool, optional): Flag to return the standard deviation data in CS format or not. Defaults to False.\n\n    Returns:\n        (numpy.ndarray): Spherical Harmonic Coefficients in SC format.\n\n    References:\n        Refer to the SHBundle or PySHBundle docs for the different data storage and retrieval formats.\n    \"\"\"\n\n    sc_mat = np.zeros((lmax+1, 2*lmax + 2))\n    dev_sc_mat = np.zeros((lmax+1, 2*lmax + 2))\n\n    # as per the convention\n    clm = data_mat[:, 2]\n    slm = data_mat[:, 3]\n    clm_std_dev = data_mat[:, 4]\n    slm_std_dev = data_mat[:, 5]\n\n    i = 0\n    for index1 in range(0,lmax+1, 1):\n        for index2 in range(0,index1+1, 1):\n\n            sc_mat[index1, lmax-index2] = slm[i]\n            sc_mat[index1, lmax+index2+1] = clm[i]\n\n            dev_sc_mat[index1, lmax-index2] = slm_std_dev[i]\n            dev_sc_mat[index1, lmax+index2+1] = clm_std_dev[i]\n\n            i = i + 1\n\n    sc_mat = np.delete(sc_mat, lmax, 1)\n    dev_sc_mat = np.delete(dev_sc_mat, lmax, 1)\n\n    if sigma_flag:\n        return sc_mat, dev_sc_mat\n    else:\n        return sc_mat\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.reshape_SH_coefficients.cs2sc","title":"<code>cs2sc(field)</code>","text":"<p>Converts SH coefficients from CS to SC format.</p> <p>Converts the square (L+1)x(L+1) matrix <code>field</code>, containing spherical harmonics coefficients in CS storage format, into a  rectangular (L+1)x(2L+1) matrix in SC format.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>ndarray</code> <p>The square (L+1)x(L+1) matrix, containing spherical harmonics coefficients in CS storage format.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Rectangular (L+1)x(2L+1) matrix in SC format.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the input is neither in CS nor in SC format.</p> <p>Examples:</p> <p>cs2sc(field)</p> Source code in <code>pyshbundle/reshape_SH_coefficients.py</code> <pre><code>def cs2sc(field):\n    \"\"\"\n    Converts SH coefficients from CS to SC format.\n\n    Converts the square (L+1)x(L+1) matrix `field`, containing\n    spherical harmonics coefficients in CS storage format, into a \n    rectangular (L+1)x(2L+1) matrix in SC format.\n\n    Args:\n        field (numpy.ndarray): The square (L+1)x(L+1) matrix, containing\n            spherical harmonics coefficients in CS storage format.\n\n    Returns:\n        (numpy.ndarray): Rectangular (L+1)x(2L+1) matrix in SC format.\n\n    Raises:\n        TypeError: If the input is neither in CS nor in SC format.\n\n    Examples:\n        cs2sc(field)\n    \"\"\"\n\n    rows = len(field)\n    cols = len(field[0])\n\n    if (rows != cols) and (cols != 2*rows - 1):\n        raise TypeError(\"Input neither in cs nor in sc format\")\n    elif cols == 2*rows - 1:\n        sc = field\n    else:\n        c    = np.tril(field)\n        ut   = np.triu(field)\n        i = np.identity(rows)\n        i = 1-i\n        s    = np.fliplr(np.transpose(np.multiply(ut, i, )))\n        sc   = np.concatenate((s[:,1:rows], c), axis=1)\n\n    return(sc)\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.reshape_SH_coefficients.klm2sc","title":"<code>klm2sc(data_mat, lmax, sigma_flag=False)</code>","text":"<p>Converts the spherical harmonic coefficients from klm format to SC format.</p> <p>Parameters:</p> Name Type Description Default <code>data_mat</code> <code>ndarray</code> <p>List containing [degree, order, clm, slm, delta clm, delta slm, start date, end date].</p> required <code>lmax</code> <code>int</code> <p>Max Degree of the spherical harmonic expansion.</p> required <code>sigma_flag</code> <code>bool</code> <p>Flag to return the standard deviation data in CS format or not. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Spherical Harmonic Coefficients or/and associated standard deviations in SC format.</p> Source code in <code>pyshbundle/reshape_SH_coefficients.py</code> <pre><code>def klm2sc(data_mat: np.ndarray, lmax: int, sigma_flag=False):\n    \"\"\"\n    Converts the spherical harmonic coefficients from klm format to SC format.\n\n    Args:\n        data_mat (numpy.ndarray): List containing [degree, order, clm, slm, delta clm, delta slm, start date, end date].\n        lmax (int): Max Degree of the spherical harmonic expansion.\n        sigma_flag (bool, optional): Flag to return the standard deviation data in CS format or not. Defaults to False.\n\n    Returns:\n        (numpy.ndarray): Spherical Harmonic Coefficients or/and associated standard deviations in SC format.\n    \"\"\"\n    sc_mat = np.zeros((lmax+1, 2*lmax + 2))\n    dev_sc_mat = np.zeros((lmax+1, 2*lmax + 2))\n    clm = data_mat[:, 2]\n    slm = data_mat[:, 3]\n    clm_std_dev = data_mat[:, 4]\n    slm_std_dev = data_mat[:, 5]\n\n    # first place the slm and then clm\n    index2 =0\n    for index1 in range(0,lmax+1,1):\n        sc_mat[index1:, lmax-index1] = slm[(index2):(index2 + lmax-index1+1)]\n        sc_mat[index1:, index1+lmax] = clm[(index2):(index2 + lmax-index1+1)]\n\n        dev_sc_mat[index1:, lmax-index1] = slm_std_dev[(index2):(index2 + lmax-index1+1)]\n        dev_sc_mat[index1:, index1+lmax] = clm_std_dev[(index2):(index2 + lmax-index1+1)]\n\n        index2 = index2 + lmax-index1+1\n\n    sc_mat=np.delete(sc_mat,lmax,axis=1)\n    dev_sc_mat=np.delete(dev_sc_mat,lmax,axis=1)\n\n    if sigma_flag:\n        return sc_mat, dev_sc_mat\n    else: \n        return sc_mat\n</code></pre>"},{"location":"convert_data_formats/#pyshbundle.reshape_SH_coefficients.sc2cs","title":"<code>sc2cs(field)</code>","text":"<p>Converts SH coefficients from SC to CS format.</p> <p>Converts the rectangular (L+1) x (2L+1) matrix <code>field</code>, containing spherical harmonics coefficients in SC storage format, into a  square (L+1) x (L+1) matrix in CS format.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>ndarray</code> <p>The rectangular (L+1) x (2L+1) matrix, containing the spherical harmonics coefficients in SC storage format.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Square (L+1) x (L+1) matrix in CS format.</p> References <p>See the SHBundle docs or PySHBundle docs for more info about SH coefficient storage and retrieval formats being implemented.</p> <p>Examples:</p> <p>sc2cs(field)</p> Source code in <code>pyshbundle/reshape_SH_coefficients.py</code> <pre><code>def sc2cs(field):\n    \"\"\"\n    Converts SH coefficients from SC to CS format.\n\n    Converts the rectangular (L+1) x (2L+1) matrix `field`, containing\n    spherical harmonics coefficients in SC storage format, into a \n    square (L+1) x (L+1) matrix in CS format.\n\n    Args:\n        field (numpy.ndarray): The rectangular (L+1) x (2L+1) matrix, containing the\n            spherical harmonics coefficients in SC storage format.\n\n    Returns:\n        (numpy.ndarray): Square (L+1) x (L+1) matrix in CS format.\n\n    References:\n        See the SHBundle docs or PySHBundle docs for more info about SH coefficient storage and retrieval formats being implemented.\n\n    Examples:\n        sc2cs(field)\n    \"\"\"\n\n    rows = len(field)\n    cols = len(field[0])\n\n    if (rows!=cols) and (cols!=2*rows - 1):\n        sc2cs.exit(\"Input neither in cs nor in sc format\")\n    elif cols == rows:\n        cs = field\n    else:\n        c    = field[:, rows-1:cols]\n        st   = np.transpose(np.fliplr(field[:, 0:rows-1]))\n        z    = np.zeros([1,rows])\n        s    = np.concatenate((st, z), axis=0)\n        cs   = np.add(c, s)\n\n    return(cs)\n</code></pre>"},{"location":"convert_data_formats/#reference","title":"Reference","text":"<ul> <li>Nico Sneeuw, Matthias Weigelt, Markus Antoni, Matthias Roth, Balaji Devaraju, et. al. (2021). SHBUNDLE 2021. http://www.gis.uni-stuttgart.de/research/projects/Bundles.</li> </ul>"},{"location":"core_functionality/","title":"Core functionality","text":"<p>The core functionality is processing spherical harmonics coefficients to mass change fields.</p>"},{"location":"core_functionality/#spherical-harmonic-analysis-and-synthesis","title":"Spherical Harmonic Analysis and Synthesis","text":"<p><code>gsha(f, method: str, grid: str = None, lmax: int = -9999):</code> </p> <p>Global Spherical Harmonic Analysis, inverse of GSHS.</p> <p>Parameters:</p> Name Type Description Default <code>f</code> <code>ndarray</code> <p>Global field of size (l_max + 1) * 2 * l_max or l_max * 2 * l_max.</p> required <code>method</code> <code>str</code> <p>Method to be used. One of: 'ls': least squares 'wls': weighted least squares 'aq': approximate quadrature 'fnm': first Neumann method 'snm': second Neumann method 'mean': block mean values (use of integrated Plm)</p> required <code>grid</code> <code>str</code> <p>Choose between 'block' or 'cell'. Defaults to None. One of: 'pole': equi-angular (l_max+1)2l_max, including poles and Greenwich meridian. 'mesh': equi-angular (l_max+1)2l_max, including poles and Greenwich meridian. 'block': equi-angular block midpoints l_max2l_max 'cell': equi-angular block midpoints l_max2l_max 'neumann': Gauss-Neumann grid (l_max+1)2l_max 'gauss': Gauss-Neumann grid (l_max+1)2l_max</p> <code>None</code> <code>lmax</code> <code>int</code> <p>Maximum degree of development. Defaults to -9999.</p> <code>-9999</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Spherical harmonics coefficients Clm, Slm in |C\\S| format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If grid argument is not 'block' or 'cell'.</p> <code>ValueError</code> <p>If grid type is not recognized.</p> <code>TypeError</code> <p>If invalid size of matrix F.</p> <code>TypeError</code> <p>If GRID and METHOD are not strings.</p> <code>ValueError</code> <p>If 2nd Neumann method is used on a non-'neumann'/'gauss' GRID.</p> <code>ValueError</code> <p>If Block mean method is used on a non-'block'/'cell' GRID.</p> <code>ValueError</code> <p>If maximum degree of development is higher than number of rows of input.</p> Notes <p>TBD - Zlm-functions option     - eigengrav, GRS80     - When 'pole' grid, m = 1 yields singular Plm-matrix!</p> Uses <p><code>plm</code>, <code>neumann</code>, <code>iplm</code>, <code>sc2cs</code></p> Author <p>Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)</p> Source code in <code>pyshbundle/pysh_core.py</code> <pre><code>def gsha(f, method: str, grid: str = None, lmax: int = -9999):\n    \"\"\"\n    Global Spherical Harmonic Analysis, inverse of GSHS.\n\n    Args:\n        f (numpy.ndarray): Global field of size (l_max + 1) * 2 * l_max or l_max * 2 * l_max.\n        method (str): Method to be used. One of:\n            'ls': least squares\n            'wls': weighted least squares\n            'aq': approximate quadrature\n            'fnm': first Neumann method\n            'snm': second Neumann method\n            'mean': block mean values (use of integrated Plm)\n        grid (str, optional): Choose between 'block' or 'cell'. Defaults to None. One of:\n            'pole': equi-angular (l_max+1)*2*l_max, including poles and Greenwich meridian.\n            'mesh': equi-angular (l_max+1)*2*l_max, including poles and Greenwich meridian.\n            'block': equi-angular block midpoints l_max*2*l_max\n            'cell': equi-angular block midpoints l_max*2*l_max\n            'neumann': Gauss-Neumann grid (l_max+1)*2*l_max\n            'gauss': Gauss-Neumann grid (l_max+1)*2*l_max\n        lmax (int, optional): Maximum degree of development. Defaults to -9999.\n\n    Returns:\n        (numpy.ndarray): Spherical harmonics coefficients Clm, Slm in |C\\S| format.\n\n    Raises:\n        ValueError: If grid argument is not 'block' or 'cell'.\n        ValueError: If grid type is not recognized.\n        TypeError: If invalid size of matrix F.\n        TypeError: If GRID and METHOD are not strings.\n        ValueError: If 2nd Neumann method is used on a non-'neumann'/'gauss' GRID.\n        ValueError: If Block mean method is used on a non-'block'/'cell' GRID.\n        ValueError: If maximum degree of development is higher than number of rows of input.\n\n    Notes:\n        TBD - Zlm-functions option\n            - eigengrav, GRS80\n            - When 'pole' grid, m = 1 yields singular Plm-matrix!\n\n    Uses:\n        `plm`, `neumann`, `iplm`, `sc2cs`\n\n    Author:\n        Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n    \"\"\"\n    rows, cols = f.shape\n\n    if cols == 2 * rows: #Check conditions\n        if lmax == -9999:\n            lmax = rows\n\n        if grid == None:\n            grid = 'block'\n\n        if (grid != 'block') and (grid != 'cell'):\n            raise ValueError(\"Your GRID variable should be either block or cell\")\n\n        n = rows\n        dt = 180 / n\n        theta = np.arange(dt/2, 180+(dt/4), dt)\n        lam = np.arange(dt/2, 360+(dt/4), dt)\n\n    elif cols == 2 * rows - 2:\n        if lmax == -9999:\n            lmax = rows - 1\n        if grid == None:\n            grid = 'pole'\n\n        n = rows - 1\n        dt = 180 / n\n\n        if (grid == 'pole') or (grid == 'mesh'):                   \n            theta = np.arange(0, 180+(dt/4), dt)\n            lam = np.arange(0, 360+(dt/4) - dt, dt)\n        elif (grid == 'neumann') or (grid == 'gauss'): \n        # gw, gx = neumann(n+1) #For some reason, grule does not work for even values\n            gw, gx = neumann(n)\n            theta = np.arccos(np.flipud(gx)) * 180 / np.pi\n            lam = np.arange(0, 360+(dt/4)-dt, dt)\n\n            if len(gw.shape) == 1:\n                gw = gw.reshape(gw.shape[0],1)\n\n            if len(gx.shape) == 1:\n                gx = gx.reshape(gx.shape[0],1)\n        else:\n            raise ValueError(\"Grid type entered is incorrect\")\n    else:\n        raise TypeError(\"Invalid size of matrix F\")\n\n    theRAD = theta * np.pi / 180\n    # if len(theRAD.shape) == 1:\n    # theRAD = theRAD.reshape(theRAD.shape[0],1)\n\n\n    # further diagnostics\n\n    if (type(grid) != str) or (type(method) != str):\n        raise TypeError(\"GRID and METHOD must be strings.\")\n\n    if (method == 'snm') and ((grid != 'neumann') and (grid != 'gauss')):\n        raise ValueError('2nd Neumann method ONLY on a ''neumann''/''gauss'' GRID')\n\n    if (method == 'mean') and ((grid != 'block') and (grid != 'cell')):\n        raise ValueError('Block mean method ONLY on a ''block''/''cell'' GRID')\n\n    if lmax &gt; n:\n        raise ValueError('Maximum degree of development is higher than number of rows of input.')\n\n    # Reshape variables as required\n\n    if len(lam.shape) == 1:\n        lam = lam.reshape(1,lam.shape[0])\n\n    # Init\n\n    L = n\n    clm = np.zeros((L+1, L+1), dtype='float')\n    slm = np.zeros((L+1, L+1), dtype='float')\n\n\n    # First step of analysis\n\n    m = np.arange(L+1).reshape(1,L+1)\n    c = np.cos((lam.T @ m) * np.pi/180)\n    s = np.sin((lam.T @ m) * np.pi/180)\n\n\n    # % preserving the orthogonality (except for 'mean' case)\n    # % we distinguish between 'block' and 'pole' type grids (in lambda)\n\n    if (grid == 'block') or (grid == 'cell'):\n        if method == 'mean':\n            dl = dt\n            c[:,0] = dl / 360\n            m = np.arange(1, L+1)\n            ms = 2 / m * np.sin(m * dl/2 * np.pi/180) / np.pi\n            c[:,1:(L+1)+1] = c[:,1:(L+1)+1] * ms  \n            s[:,1:(L+1)+1] = s[:,1:(L+1)+1] * ms\n\n        else:\n            c = c/L\n            s = s/L\n            c[:,0] = c[:,1]/2\n            s[:,L] = s[:,L]/2\n            c[:,L] = np.zeros(2*n)\n            s[:,0] = np.zeros(2*n)\n    else:\n        c = c/L\n        s = s/L\n        c[:,[0, L]] = c[:,[0, L]]/2\t\n        s[:,[0, L]] = np.zeros((2*n,2))\t  \n\n\n    a = f @ c\n    b = f @ s    \n\n    # Second step of analysis: Clm and Slm\n\n    if method == 'ls':\n        for m in range(L+1):\n#            l = np.arange(m,L+1)\n            l = np.arange(m,L+1).reshape(L+1-m, 1)\n            l = l.T\n\n            p = plm(l,m,theRAD, 3, 1)\n            p = p[:,:,0]\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m+1:L+2, m+1] = linalg.lstsq(p, ai)\n            slm[m+1:L+2, m+1] = linalg.lstsq(p, bi)\n\n\n    elif method == 'aq': #Approximate Quadrature\n        si = np.sin(theRAD)\n        si = 2 * si / np.sum(si)\n\n        for m in range(L+1):\n            l = np.arange(m, L+1).reshape(L+1-m, 1)\n            l = l.T\n\n            p = plm(l,m,theRAD, 3, 1)\n\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (si * ai)\n            slm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (si * bi)\n\n    elif method == 'fnm': #1st Neumann method (exact upto L/2)\n        w = neumann(np.cos(theRAD))\n\n        for m in range(L+1):\n            l = np.arange(m, L+1).reshape(L+1-m, 1)\n            l = l.T\n\n            p = plm(l,m,theRAD, 3, 1)\n\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (w * ai)\n            slm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (w * bi)\n\n    elif method == 'snm': #2nd Neumann method (exact)\n        for m in range(L+1):\n            l = np.arange(m, L+1).reshape(L+1-m, 1)\n            l = l.T\n\n            p = plm(l,m,theRAD, 3, 1)\n\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (gw * ai)\n            slm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ (gw * bi)\n\n    elif method == 'mean':\n        for m in range(L+1):\n            print(m)\n            #l = np.arange(m,L+1).reshape(L+1-m,1)\n            #l = l.T\n\n\n            l = np.array([np.arange(m,L+1, 1)])\n        # l = np.array([[m]])\n\n            p = iplm(l,m,theRAD)\n        # p = p[:,-1]\n            ai = a[:, m]\n            bi = b[:, m]\n\n            clm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ ai\n            slm[m:L+1, m] = (1 + (m == 0))/ 4 * p.T @ bi\n\n    # Write the coefficients Clm &amp; Slm in |C\\S| format\n\n    slm = np.fliplr(slm)\n    cs = sc2cs(np.concatenate((slm[:, np.arange(L)], clm), axis = 1))\n    cs = cs[:int(lmax+1), :int(lmax+1)]\n\n\n    return cs\n</code></pre> <p><code>gshs(field, quant = 'none', grd = 'mesh', n = -9999, h = 0, jflag = 1):</code> </p> <p>Global Spherical Harmonic Synthesis.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <code>ndarray</code> <p>Matrix of SH coefficients, either in SC-triangle or CS-square format.</p> required <code>quant</code> <code>str</code> <p>Defines the field quantity. Defaults to 'none'. One of: 'geoid': geoid height [m] 'potential': potential [m^2/s^2] 'dg', 'gravity': gravity anomaly [mGal] 'tr': grav. disturbance, 1st rad. derivative [mGal] 'trr': 2nd rad. derivative [1/s^2] 'water': equivalent water height [m] 'smd': surface mass density [kg/m^2]</p> <code>'none'</code> <code>grd</code> <code>str</code> <p>Defines the grid. Defaults to 'mesh'. One of: 'pole', 'mesh': equi-angular (n+1)2n, includes poles/Greenwich meridian. 'block', 'cell': equi-angular block midpoints, n2n. 'neumann', 'gauss': Gauss-grid (n+1)*2n.</p> <code>'mesh'</code> <code>n</code> <code>int</code> <p>Degree of harmonics. Defaults to -9999 (lmax).</p> <code>-9999</code> <code>h</code> <code>int</code> <p>Height above Earth mean radius [m]. Defaults to 0.</p> <code>0</code> <code>jflag</code> <code>int</code> <p>Subtracts GRS80 when set. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <p>numpy.ndarray: The global Spherical Harmonics field.</p> <p>numpy.ndarray: Vector of co-latitudes in radians.</p> <p>numpy.ndarray: Vector of longitudes in radians.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the format of the field is incorrect.</p> <code>Exception</code> <p>If n is not scalar.</p> <code>Exception</code> <p>If n is not an integer.</p> <code>Exception</code> <p>If the grid argument is not a string.</p> Uses <p><code>cs2sc</code>, <code>normalklm</code>, <code>plm</code>, <code>eigengrav</code>, <code>ispec</code></p> Todo <ul> <li>Change general exceptions to specific and descriptive built-in ones.</li> <li>Using the not and then check is not always advisable.</li> <li>Check how to document valid options.</li> </ul> Author <p>Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc) Vivek Kumar Yadav, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)</p> Source code in <code>pyshbundle/pysh_core.py</code> <pre><code>def gshs(field, quant = 'none', grd = 'mesh', n = -9999, h = 0, jflag = 1):\n    \"\"\"\n    Global Spherical Harmonic Synthesis.\n\n    Args:\n        field (numpy.ndarray): Matrix of SH coefficients, either in SC-triangle or CS-square format.\n        quant (str, optional): Defines the field quantity. Defaults to 'none'. One of:\n            'geoid': geoid height [m]\n            'potential': potential [m^2/s^2]\n            'dg', 'gravity': gravity anomaly [mGal]\n            'tr': grav. disturbance, 1st rad. derivative [mGal]\n            'trr': 2nd rad. derivative [1/s^2]\n            'water': equivalent water height [m]\n            'smd': surface mass density [kg/m^2]\n        grd (str, optional): Defines the grid. Defaults to 'mesh'. One of:\n            'pole', 'mesh': equi-angular (n+1)*2n, includes poles/Greenwich meridian.\n            'block', 'cell': equi-angular block midpoints, n*2n.\n            'neumann', 'gauss': Gauss-grid (n+1)*2n.\n        n (int, optional): Degree of harmonics. Defaults to -9999 (lmax).\n        h (int, optional): Height above Earth mean radius [m]. Defaults to 0.\n        jflag (int, optional): Subtracts GRS80 when set. Defaults to 1.\n\n    Returns:\n        numpy.ndarray: The global Spherical Harmonics field.\n        numpy.ndarray: Vector of co-latitudes in radians.\n        numpy.ndarray: Vector of longitudes in radians.\n\n    Raises:\n        Exception: If the format of the field is incorrect.\n        Exception: If n is not scalar.\n        Exception: If n is not an integer.\n        Exception: If the grid argument is not a string.\n\n    Uses:\n        `cs2sc`, `normalklm`, `plm`, `eigengrav`, `ispec`\n\n    Todo:\n        * Change general exceptions to specific and descriptive built-in ones.\n        * Using the not and then check is not always advisable.\n        * Check how to document valid options.\n\n    Author:\n        Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n        Vivek Kumar Yadav, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n    \"\"\"\n\n    wd = getcwd()\n    chdir(wd)\n\n    rows, cols = field.shape\n\n    if rows == cols:                    #field in CS-format \n        lmax = rows - 1\n        field = cs2sc(field)\n    elif cols - 2 * rows == -1:         #field in SC-format already\n        lmax = rows - 1\n    else:\n        raise Exception(\"Check format of the field\")\n\n    if n == -9999:                      #(no value of n is input) -&gt; set n = lmax\n        n = lmax\n\n    if not np.isscalar(n):\n        raise Exception(\"n must be scalar\")\n\n    if not np.issubdtype(type(n), np.integer):\n        raise Exception(\"n must be integer\")\n\n    if not type(grd) == str:\n        raise Exception(\"Grid argument must be string\")\n\n    grd = grd.lower()\n\n\n\n    #Grid Definition\n    dt = np.pi/n\n\n    if grd == 'pole' or grd == 'mesh':\n        theRAD = np.arange(0, np.pi+dt*0.5, dt, dtype='float')\n        lamRAD = np.arange(0, 2*np.pi, dt, dtype='float')\n    elif grd == 'block' or grd == 'cell':\n        theRAD = np.arange(dt/2, np.pi + dt*0.5, dt, dtype='float')\n        lamRAD = np.arange(dt/2, 2*np.pi + dt*0.5, dt, dtype='float')\n    else:\n        raise Exception(\"Incorrect grid type input\")\n\n    nlat = len(theRAD)\n    nlon = len(lamRAD)\n\n\n\n#   -------------------------------------------------------------------------\n#   Preprocessing on the coefficients:\n        # - subtract reference field (if jflag is set)\n        # - specific transfer\n        # - upward continuation\n#   -------------------------------------------------------------------------\n\n    if jflag:\n        field = field - cs2sc(normalklm(lmax+1))\n\n    l = np.arange(0, lmax+1)\n    transf = np.array([eigengrav(lmax, quant, h)])[0, :, :].T\n\n    field = field * np.matmul(transf, np.ones((1, 2*lmax+1)), dtype='float')\n\n\n\n# -------------------------------------------------------------------------\n        # Size declarations and start the waitbar:\n        # Note that the definition of dlam causes straight zero-padding in case N &gt; L.\n        # When N &lt; L, there will be zero-padding up to the smallest integer multiple\n        # of N larger than L. After the Fourier transformation (see below), the\n        # proper samples have to be picked out, with stepsize dlam.\n# -------------------------------------------------------------------------\n\n\n    dlam = int(np.ceil(lmax/n))             #longitude step size\n    abcols = dlam*n + 1                     #columns required in A and B\n    a = np.zeros((nlat, int(abcols)), dtype='float')\n    b = np.zeros((nlat, int(abcols)), dtype='float')\n\n\n\n    m = 0\n    c = field[m:lmax+1, lmax+m] \n    l = np.array([np.arange(m,lmax+1)])\n    p = plm(l, m, theRAD, nargin = 3, nargout = 1)[:,:,0]\n    a[:, m] = np.dot(p,c) \n    b[:, m] = np.zeros(nlat) \n\n\n\n    for m in range(1,lmax+1,1):\n        c = field[m:lmax+1,lmax+m]\n        s = field[m:lmax+1,lmax-m]\n\n        l = np.array([np.arange(m,lmax+1)])\n        p = plm(l, m, theRAD, nargin = 3, nargout = 1)[:,:,0]\n        a[:, m] = np.dot(p,c)\n        b[:, m] = np.dot(p,s)\n\n    del field\n\n\n#   -------------------------------------------------------------------------\n        # The second synthesis step consists of an inverse Fourier transformation\n        # over the rows of a and b. \n        # In case of 'block', the spectrum has to be shifted first.\n        # When no zero-padding has been applied, the last b-coefficients must be set to\n        # zero. Otherwise the number of longitude samples will be 2N+1 instead of 2N.\n        # For N=L this corresponds to setting SLL=0!\n#  -------------------------------------------------------------------------\n\n\n    if grd =='block' or grd == 'cell': \n      m      = np.arange(0,abcols,1)\n      cshift = np.array([np.ones(nlat)], dtype='float').T * np.array([np.cos(m*np.pi/2/n)], dtype='float');\t# cshift/sshift describe the \n      sshift = np.array([np.ones(nlat)], dtype='float').T * np.array([np.sin(m*np.pi/2/n)], dtype='float');\t# half-blocksize lambda shift.\n      atemp  =  cshift*a + sshift*b\n      b      = -sshift*a + cshift*b\n      a      = atemp\n\n\n\n    if np.remainder(n,lmax) == 0:               #Case without zero-padding\n        b[:,abcols-1] = np.zeros(nlat)\n\n    #Code for ispec\n\n    f = ispec(a.T, b.T).T\n    if dlam &gt; 1: \n        f = f[:,np.arange(1,dlam*nlon+1,dlam)]\n\n    return f, theRAD, lamRAD\n</code></pre> <p><code>PhaseCalc(fts, ffts):</code> </p> <p>Calculates the phase difference between two time series based on the Hilbert transform method explained by Phillip et al.</p> <p>Parameters:</p> Name Type Description Default <code>fts</code> <code>ndarray</code> <p>Time-series 1.</p> required <code>ffts</code> <code>ndarray</code> <p>Time-series 2.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Phase difference between the two time series.</p> References <p>Phillips, T., R. S. Nerem, B. Fox-Kemper, J. S. Famiglietti, and B. Rajagopalan (2012), The influence of ENSO on global terrestrial water storage using GRACE, Geophysical Research Letters, 39 (16), L16,705, doi:10.1029/2012GL052495.</p> Author <p>Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)</p> Source code in <code>pyshbundle/pysh_core.py</code> <pre><code>def PhaseCalc(fts, ffts):\n    \"\"\"\n    Calculates the phase difference between two time series based on the\n    Hilbert transform method explained by Phillip et al.\n\n    Args:\n        fts (numpy.ndarray): Time-series 1.\n        ffts (numpy.ndarray): Time-series 2.\n\n    Returns:\n        (numpy.ndarray): Phase difference between the two time series.\n\n    References:\n        Phillips, T., R. S. Nerem, B. Fox-Kemper, J. S. Famiglietti, and B. Rajagopalan (2012),\n        The influence of ENSO on global terrestrial water storage using GRACE, Geophysical\n        Research Letters, 39 (16), L16,705, doi:10.1029/2012GL052495.\n\n    Author:\n        Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n    \"\"\"\n    c = fts.shape[1]\n\n    ps = np.zeros((1, c))\n\n    filter_ = ~np.isnan(fts)\n    filter__ = ~np.isnan(ffts)\n\n    fts_ = fts[filter_] #Extract values and leave Nan\n    ffts_ = ffts[filter__] #Extract values and leave Nan\n\n    fts = fts_.reshape(int(fts_.shape[0]/c),c)\n    ffts = ffts_.reshape(int(ffts_.shape[0]/c),c)\n\n    rn = fts.shape[0]\n\n    for i in range(c):\n        # A = np.concatenate(np.ones((rn,1)), np.real(signal.hilbert(ffts[:, i])), np.imag(signal.hilbert(ffts[:, i]))) #design matrix\n\n        A = np.array((np.ones((rn)), np.real(signal.hilbert(ffts[:, i])), np.imag(signal.hilbert(ffts[:, i])))).T\n\n        A = A.astype('double')\n        B = fts[:,i]\n        B = B.astype('double')\n        abc = np.linalg.lstsq(A.T @ A, A.T @ B)[0]\n\n        ps[0,i] = np.arctan2(abc[3-1],abc[2-1])*(180/np.pi) #check indices and degree/radian\n    return ps\n</code></pre>"},{"location":"core_functionality/#intro-to-grace-data-driven-correction","title":"Intro to Grace Data Driven Correction","text":"<p><code>GRACE_Data_Driven_Correction_Vishwakarma(F, cf, GaussianR, basins):</code> </p> <p>Signal leakage correction using data-driven methods.</p> <p>When GRACE data is applied for hydrological studies, the signal leakage is a common problem. This function uses data-driven methods to correct signal leakage in GRACE data. Please refer to paper (1) above for more details.</p> <p>Parameters:</p> Name Type Description Default <code>F</code> <code>ndarray</code> <p>A cell matrix with one column containing SH coefficients.</p> required <code>cf</code> <code>int</code> <p>The column in F that contains SH coefficients from GRACE.</p> required <code>GaussianR</code> <code>float</code> <p>Radius of the Gaussian filter (recommended = 400).</p> required <code>basins</code> <code>ndarray</code> <p>Mask functions of basin, a cell data format with one column and each entry is a 360 x 720 matrix with 1 inside the catchment and 0 outside.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing: - RecoveredTWS (numpy.ndarray): Corrected data-driven time-series (Least Squares fit method). - RecoveredTWS2 (numpy.ndarray): Corrected data-driven time-series (shift and amplify method). - FilteredTS (numpy.ndarray): Gaussian filtered GRACE TWS time-series for all the basins.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there is an error in the corrected data-driven time-series (Least Squares fit method).</p> <code>Exception</code> <p>If there is an error in the corrected data-driven time-series (shift and amplify method).</p> <code>Exception</code> <p>If there is an error in the Gaussian filtered GRACE TWS time-series for all the basins.</p> Author <p>Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)</p> Source code in <code>pyshbundle/pysh_core.py</code> <pre><code>def GRACE_Data_Driven_Correction_Vishwakarma(F, cf, GaussianR, basins):\n    \"\"\"\n    Signal leakage correction using data-driven methods.\n\n    When GRACE data is applied for hydrological studies, the signal leakage is a common\n    problem. This function uses data-driven methods to correct signal leakage in GRACE data.\n    Please refer to paper (1) above for more details.\n\n    Args:\n        F (numpy.ndarray): A cell matrix with one column containing SH coefficients.\n        cf (int): The column in F that contains SH coefficients from GRACE.\n        GaussianR (float): Radius of the Gaussian filter (recommended = 400).\n        basins (numpy.ndarray): Mask functions of basin, a cell data format with one\n            column and each entry is a 360 x 720 matrix with 1 inside the\n            catchment and 0 outside.\n\n    Returns:\n        tuple: A tuple containing:\n            - RecoveredTWS (numpy.ndarray): Corrected data-driven time-series (Least Squares fit method).\n            - RecoveredTWS2 (numpy.ndarray): Corrected data-driven time-series (shift and amplify method).\n            - FilteredTS (numpy.ndarray): Gaussian filtered GRACE TWS time-series for all the basins.\n\n    Raises:\n        Exception: If there is an error in the corrected data-driven time-series (Least Squares fit method).\n        Exception: If there is an error in the corrected data-driven time-series (shift and amplify method).\n        Exception: If there is an error in the Gaussian filtered GRACE TWS time-series for all the basins.\n\n    Author:\n        Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n    \"\"\"\n    deg = 0.5\n    x = np.linspace(0, 360-deg, int(360/deg))\n    y = np.linspace(0, 180-deg, int(180/deg))\n    x1 = np.linspace(deg, 360, int(360/deg))\n    y1 = np.linspace(deg, 180, int(180/deg))\n    lambdd,theta = np.meshgrid(x,y)  \n    lambdd1,theta1 = np.meshgrid(x1,y1)\n\n    theta_rad = deg_to_rad(theta)\n    theta1_rad = deg_to_rad(theta1)\n\n    #Areahalfdeg = (6378.137**2)*np.power(10,6)*np.pi/180*(np.multiply(a,b)) #Area matrix\n    Areahalfdeg = (6378.137**2)*(((np.pi/180)*lambdd1) - ((np.pi/180)*lambdd))*(np.sin((np.pi/2) - theta_rad) - np.sin((np.pi/2) - theta1_rad))\n\n    qty = 'water'\n\n    if type(F) != np.ndarray:\n        raise Exception(\"input GRACE field should be in Numpy Ndarray format, please check guidelines\")\n\n\n    if type(basins) != np.ndarray:\n        raise Exception(\"input basin field should be in Numpy NdArray format, please check guidelines\")\n\n\n    r = F.shape[0] #No of entries in F numpy ndarrray\n\n    cid = 1 #number of river catchments\n\n    f = F[:,cf-1:cf]\n    l = f[0][0].shape[0]\n    cfield = f[0][0].shape[1]\n    if cfield == l:\n        flag_cs = 0\n    else:\n        flag_cs = 1\n\n    Weights = Gaussian(l-1, GaussianR) \n    #gaussian returns weights as a list #gaussian is np.array()\n\n    try: #Broadcase Weights into dimensions\n        filter_ = np.ones([1,(2*(l-1))+1]) * Weights\n    except:\n        w0 = Weights.shape[0]\n        Weights = Weights.reshape(w0,1)\n        filter_ = np.ones([1,(2*(l-1))+1]) * Weights\n\n\n    #SH Synthesis\n    if l == cfield:\n        for m in range(r):\n            if flag_cs == 0:\n                Ft = cs2sc(f[m][0]).astype('double') \n            else:\n                Ft = f[m][0].astype('double') \n\n\n            fFld__, _, _ = gshs(Ft * filter_, qty, 'cell', int(180/deg), 0, 0) \n            ffFld__, _, _ = gshs((Ft * filter_ * filter_), qty, 'cell', int(180/deg), 0, 0)\n\n            if m == 0:\n                fFld = np.zeros((r,fFld__.shape[0],fFld__.shape[1]), dtype='double') \n                ffFld = np.zeros((r, ffFld__.shape[0], ffFld__.shape[1]), dtype='double')\n\n            fFld[m] = fFld__\n            ffFld[m] = ffFld__\n\n        long = 360/deg\n        Area = Areahalfdeg\n    else:\n        raise Exception(\"enter CS coefficients\")\n\n\n\n    #Declaration of size of the vectors:\n    cid = len(basins) #Here basins is a dictionary with each element storing nd array\n    tsleaktotalf = np.zeros([r, cid], dtype='double')\n    tsleaktotalff = np.zeros([r, cid], dtype='double')\n\n    ftsleaktotal = np.zeros([r, cid], dtype='double')\n    fftsleaktotal = np.zeros([r, cid], dtype='double')\n\n    lhat = np.zeros([r, cid], dtype='double')\n\n    bfDevRegAv = np.zeros([r, cid], dtype='double')\n    bbfDevRegAv = np.zeros([r, cid], dtype='double')\n\n    FilteredTS = np.zeros([r, cid], dtype='double')\n    filfilts = np.zeros([r, cid], dtype='double')\n\n    leakage = np.zeros([r, cid], dtype='double')\n    leakager = np.zeros([r, cid], dtype='double')   \n\n\n\n    for rbasin in range(0, cid):\n        #Get the basin functions ready\n\n        #Basin functions, filtered basin function and transfer function Kappa\n        Rb = basins[rbasin][0] \n        csRb = gsha(Rb, 'mean', 'block', long/2) \n        csF = cs2sc(csRb[0:l, 0:l]) \n        filRb_ = gshs(csF * filter_, 'none', 'cell', int(long/2), 0, 0) \n        filRb = filRb_[0]\n        kappa = (1-Rb) * filRb\n\n\n\n        fF = np.zeros((fFld__.shape[0],fFld__.shape[1]), dtype='double')\n        ffF = np.zeros((fFld__.shape[0],fFld__.shape[1]), dtype='double')\n        for m in range(0,r):\n\n\n            fF = np.concatenate((fFld[m,:,int(fF.shape[1]/2):], fFld[m,:,:int(fF.shape[1]/2)]), axis=1)\n            ffF = np.concatenate((ffFld[m,:,int(ffF.shape[1]/2):], ffFld[m,:,:int(ffF.shape[1]/2)]), axis=1)\n            #if False:    \n            if np.isnan(fF[:20,:20]).any(): #if there is a gap in time series, fill it with NaNs\n\n\n                tsleaktotalf[m][rbasin] = np.nan\n                tsleaktotalff[m][rbasin] = np.nan\n                FilteredTS[m][rbasin] = np.nan\n                filfilts[m][0:rbasin] = np.nan\n                bfDevRegAv[m][rbasin] = np.nan\n                bbfDevRegAv[m][0:rbasin] = np.nan\n\n            else:\n                #leakage time series from filtered and twice filtered fields\n                tsleaktotalf[m][rbasin] = np.sum(fF * kappa * Area) / np.sum(Rb * Area)\n                tsleaktotalff[m][rbasin] = np.sum(ffF * kappa * Area) / np.sum(Rb * Area)\n\n                #time series from filtered fields\n                FilteredTS[m][rbasin] = np.sum(fF * Rb * Area) / np.sum(Rb * Area)\n                filfilts[m][rbasin] = np.sum(ffF * Rb * Area) / np.sum(Rb * Area)\n\n                #Deviation integral timeseries\n                bfDevRegAv[m][rbasin] = np.sum((fF * Rb - FilteredTS[m][rbasin]) * filRb * Area) / np.sum(Rb * Area) #working 2022-10-20\n                bbfDevRegAv[m][rbasin] = np.sum((ffF * Rb - filfilts[m][rbasin]) * filRb * Area) / np.sum(Rb * Area)\n                print(m)\n\n\n\n\n\n    b = list()\n    bl = list()\n    for i in range(0, cid):\n\n        A = np.ones([60,2])\n        A[:,1] = naninterp(bbfDevRegAv[:, i]) #Pchip interpolate should contain atleast two elements\n\n        lssol_ = sc.linalg.lstsq(A, naninterp(bfDevRegAv[:, i])) #returns a tuple of solution \"x\", residue and rank of matrix A; for A x = B\n        lssol = lssol_[0] \n\n        b.append(lssol[2-1])\n\n\n        A = np.ones([60,2])\n        A[:,1] = naninterp(tsleaktotalff[:, i])\n        lssol_ = sc.linalg.lstsq(A, naninterp(tsleaktotalf[:, i])) #returns a tuple of solution \"x\", residue and rank of matrix A; for A x = B\n        lssol = lssol_[0]\n        bl.append(lssol[2-1])\n        #Working till here 2022-10-21 1530pm\n\n    multp = npm.repmat(b, r, 1) \n    devint = bfDevRegAv * multp\n    multp = npm.repmat(bl, r, 1)\n    leakLS = tsleaktotalf * multp\n\n\n    ps = PhaseCalc(tsleaktotalf,tsleaktotalff)\n\n\n\n    #Compute the near true leakage\n\n    for i in range(0, cid):   \n        ftsleaktotal[:,i] = naninterp(tsleaktotalf[:,i]) #Replaces gaps (NaN values) with an itnerpolated value in the leakage time series from once filtered fields\n        fftsleaktotal[:,i] = naninterp(tsleaktotalff[:,i]) #replace the gaps (NaN values) with an interpolated value in leakage time series from twice filtered fields\n\n        X = sc.fft.fft(ftsleaktotal[:,i]) #take fast Fourier transform #check shape of X 2022-10-21\n        p = -ps[0,i] / r #compute the fraction of the time period by which the time series is to be shiftes\n        Y = np.exp(1j * np.pi * p * ((np.arange(r)) - r/2) / r) #compute the Conjugate-Symmetric shift \n        Z = X * Y #Apply the shift\n\n        a = sc.fft.ifft(Z) #apply inverse fft\n\n        con = np.conj(a)\n\n        s = a + con\n\n        z = s/2\n\n        leakage[:,i] = z #shifted timeseries\n\n\n        #Shift timeseriecs from once filtered fields in the direction of the time series from twice filtered fields, to later compute the amplitude ratio\n        p = ps[0,i] / r #Fraction of a time period to shift data\n        Y = np.exp(1j * np.pi * p * ((np.arange(r)) - r/2) / r) #compute the Conjugate-Symmetric shift\n        Z = X * Y\n\n        a = sc.fft.ifft(Z) #apply inverse fft\n\n        con = np.conj(a)\n\n        s = a + con\n\n        z = s/2\n\n        leakager[:,i] = z #shifted timeseries\n\n\n\n    #compute the ratio between the amplitude of the shifted leakage from once filtered fields and leakage from twice filtered fields\n    rfn = leakage/fftsleaktotal\n    rfn[(rfn) &gt;= 2] = 1\n    rfn[(rfn) &lt;= -2] = -1\n    rfn = np.sum(np.abs(rfn), axis = 0)\n    rfn=rfn/r # amplitude ratio\n\n\n    lhat = leakager * rfn #apply the amplitude ratio to the shifted leakage timeseries from the once filtered fields to get the near true leakage\n    lhat[np.isnan(FilteredTS)] = np.nan #reintroduce nan for data gaps\n    leakLS[np.isnan(FilteredTS)] = np.nan\n    RecoveredTWS = FilteredTS - leakLS - devint\n    RecoveredTWS2 = FilteredTS - lhat - devint\n\n    return RecoveredTWS, RecoveredTWS2, FilteredTS\n</code></pre>"},{"location":"core_functionality/#hydrological-applications-with-grace","title":"Hydrological Applications with GRACE","text":"<p><code>Basinaverage(temp, gs, shp_basin, basin_area):</code> </p> <p>Calculate the basin average of the total water storage (TWS) from the gridded TWS data.</p> <p>Applies area weighting to the gridded TWS data and then clips the data to the basin shapefile. Followed by summation of data over the latitude and longitude dimensions, divides it by basin area to get the basin average TWS.</p> <p>Parameters:</p> Name Type Description Default <code>temp</code> <code>DataArray</code> <p>Gridded total water storage data.</p> required <code>gs</code> <code>float</code> <p>Grid size.</p> required <code>shp_basin</code> <code>GeoDataFrame</code> <p>Shapefile of the basin.</p> required <code>basin_area</code> <code>float</code> <p>Area of the basin in square meters.</p> required <p>Returns:</p> Name Type Description <code>basin_tws</code> <code>DataArray</code> <p>Total water storage data clipped to the basin.</p> <code>basin_avg_tws</code> <code>DataArray</code> <p>Basin average total water storage.</p> Source code in <code>pyshbundle/hydro.py</code> <pre><code>def Basinaverage(temp, gs, shp_basin, basin_area):\n    \"\"\"\n    Calculate the basin average of the total water storage (TWS) from the gridded TWS data.\n\n    Applies area weighting to the gridded TWS data and then clips the data to the basin shapefile.\n    Followed by summation of data over the latitude and longitude dimensions, divides it by basin\n    area to get the basin average TWS.\n\n    Args:\n        temp (xarray.DataArray): Gridded total water storage data.\n        gs (float): Grid size.\n        shp_basin (geopandas.GeoDataFrame): Shapefile of the basin.\n        basin_area (float): Area of the basin in square meters.\n\n    Returns:\n        basin_tws (xarray.DataArray): Total water storage data clipped to the basin.\n        basin_avg_tws (xarray.DataArray): Basin average total water storage.\n    \"\"\"\n\n    from pyshbundle.hydro import area_weighting\n    # area_weighting returns the area of each grid in m^2 for the grid resolution specified\n    temp_weighted=temp.copy()\n    temp_weighted['tws']=temp['tws']*area_weighting(gs)\n\n    ''' add projection system to nc '''\n    basin_tws = temp_weighted.rio.write_crs(\"EPSG:4326\", inplace=True)\n    basin_tws = basin_tws.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n\n    # mask data with shapefile\n    basin_tws = basin_tws.rio.clip(shp_basin.geometry.apply(mapping), shp_basin.crs,drop=True)\n    basin_avg_tws=basin_tws.sum(dim=('lon','lat'), skipna=True)/basin_area  #basin average tws\n\n    basin_tws=basin_tws.drop_vars('spatial_ref')\n    basin_avg_tws=basin_avg_tws.drop_vars('spatial_ref')\n\n    return basin_tws, basin_avg_tws\n</code></pre> <p><code>TWSCalc(data, lmax: int, gs: float, r:float, m: int):</code> </p> <p>Spherical Harmonics Synthesis for Total Water Storage (TWS) calculation.</p> <p>Calculate the total water storage (TWS) from spherical harmonics coefficients. Uses spherical harmonics synthesis to go from harmonics to gridded domain.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Spherical harmonics coefficients in SC format.</p> required <code>lmax</code> <code>int</code> <p>Maximum degree of the spherical harmonics coefficients.</p> required <code>gs</code> <code>float</code> <p>Grid size.</p> required <code>r</code> <code>float</code> <p>Half-width of the Gaussian filter.</p> required <code>m</code> <code>int</code> <p>Number of time steps.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Gridded TWS data.</p> Uses <p>'Gaussian', 'gshs'</p> Author <p>Vivek Yadav, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)</p> Source code in <code>pyshbundle/hydro.py</code> <pre><code>def TWSCalc(data, lmax: int, gs: float, r:float, m: int):\n    \"\"\"\n    Spherical Harmonics Synthesis for Total Water Storage (TWS) calculation.\n\n    Calculate the total water storage (TWS) from spherical harmonics coefficients.\n    Uses spherical harmonics synthesis to go from harmonics to gridded domain.\n\n    Args:\n        data (numpy.ndarray): Spherical harmonics coefficients in SC format.\n        lmax (int): Maximum degree of the spherical harmonics coefficients.\n        gs (float): Grid size.\n        r (float): Half-width of the Gaussian filter.\n        m (int): Number of time steps.\n\n    Returns:\n        (numpy.ndarray): Gridded TWS data.\n\n    Uses:\n        'Gaussian', 'gshs'\n\n    Author:\n        Vivek Yadav, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n    \"\"\"\n    SC = data\n\n    gfilter = Gaussian(lmax,r)\n    grid_y = int(180/gs)\n    grid_x = int(360/gs)\n    tws_f = np.zeros([m,grid_y,grid_x], dtype ='float')\n    for i in tqdm(range(0,m,1)):\n        field = SC[i,0:lmax+1,96-lmax:96+lmax+1]\n        shfil = np.zeros([lmax+1,2*lmax+1])\n\n        for j in range(0,2*lmax+1,1):\n            shfil[:,j] = gfilter[:,0] * field[:,j]\n\n        quant = 'water' \n        grd = 'cell'\n        n = int(180/gs) \n        h = 0 \n        jflag = 0\n\n        ff = gshs(shfil, quant, grd, n, h, jflag)[0]\n\n        ff = ff*1000    # convert units from m to mm\n        tws_f[i,:,0:int(grid_x/2)] = ff[:,int(grid_x/2):]\n        tws_f[i,:,int(grid_x/2):] = ff[:,0:int(grid_x/2)]   \n\n    plt.imshow(tws_f[0,:,:])\n    return(tws_f)\n</code></pre>"},{"location":"faq/","title":"FAQ","text":"<p>Work in Progress...</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install pyshbundle, run this command in your terminal:</p> <p>This is the preferred method to install pyshbundle, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p> <pre><code># clone the repository in order to access the notebooks and data\n$ git clone https://github.com/lsmvivek/pyshbundle.git\n$ pip install .\n\n\n# The package is available on pip but is BROKEN\n# Please avoid installing via pip till we fix that\n\n# creating a new virtual environment\n$ python3 -m venv &lt;name-env&gt;\n# activate the virtual environment environment\n$ source &lt;/location-of-virt-env/name-env/bin/activate&gt;\n# install package into virtual environment\n$ pip install pyshbundle\n\n# clone the repository in order to access the notebooks and data\n$ git clone https://github.com/lsmvivek/pyshbundle.git\n</code></pre>"},{"location":"installation/#from-the-source-for-devscontributors","title":"From the source - for Devs/Contributors","text":"<p>Developers can access the latest development branch and </p> <pre><code># clone the repo and fetch the dev branch\n$ git clone https://github.com/lsmvivek/pyshbundle.git\n\n# creating a new virtual environment\n$ python3 -m venv &lt;name-env&gt;\n\n# install the dependencies from the requirements-dev file\n$ pip install -r ../pyshbundle/requirements-dev.txt\n\n# activate the virtual environment environment\n$ source &lt;/location-of-virt-env/name-env/bin/activate&gt;\n\n# install package into virtual environment\n$ pip install ../pyshbundle/dist/&lt;required-version&gt;.tar.gz\n\n# you also have the option to build the module using, be careful of \n$ python setup.py sdist\n</code></pre>"},{"location":"license/","title":"License:","text":"<pre><code>This file is part of PySHbundle.\nPySHbundle is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or\n(at your option) any later version.\n\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.\n</code></pre>"},{"location":"load_data/","title":"Load Data","text":"<p><code>pyshbundle</code> contains scripts to seemlessly extract and load spherical harmonics coefficients from various data centres. See Tutorials</p>"},{"location":"load_data/#_1","title":"Load Data","text":""},{"location":"load_data/#pyshbundle.io.extract_SH_data","title":"<code>extract_SH_data(file_path, source)</code>","text":"<p>Extracts the spherical harmonic coefficients from all the given files.</p> <p>Currently supports JPL, CSR, and ITSG data sources ONLY. Extracts the spherical harmonic  coefficients from the given file and returns them in a dictionary. Uses the degree and  order of a coefficient as the key and the coefficient values as the value.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Absolute path to the file.</p> required <code>source</code> <code>str</code> <p>Source of the data (JPL, CSR, or ITSG).</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the coefficients and time coverage start and end dates.</p> Source code in <code>pyshbundle/io.py</code> <pre><code>def extract_SH_data(file_path, source):\n    \"\"\"\n    Extracts the spherical harmonic coefficients from all the given files.\n\n    Currently supports JPL, CSR, and ITSG data sources ONLY. Extracts the spherical harmonic \n    coefficients from the given file and returns them in a dictionary. Uses the degree and \n    order of a coefficient as the key and the coefficient values as the value.\n\n    Args:\n        file_path (str): Absolute path to the file.\n        source (str): Source of the data (JPL, CSR, or ITSG).\n\n    Returns:\n        (dict): Dictionary containing the coefficients and time coverage start and end dates.\n    \"\"\"\n    # Initialize an empty dictionary to store the coefficients and dates\n    data = {\n        'coefficients': {},\n        'time_coverage_start': None,\n        'time_coverage_end': None\n    }\n\n\n    # Regular expression pattern to match the lines with coefficients\n    coeff_pattern_csr = re.compile(r'^GRCOF2\\s+(\\d+)\\s+(\\d+)\\s+([-+]?\\d*\\.\\d+E[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+E[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+E[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+E[-+]?\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+')\n    coeff_pattern_jpl = re.compile(r'^GRCOF2\\s+(\\d+)\\s+(\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)')\n    coeff_pattern_itsg = re.compile(r'^gfc\\s+(\\d+)\\s+(\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)$')\n\n\n    if source=='jpl': coeff_pattern=coeff_pattern_jpl\n    elif source=='csr': coeff_pattern=coeff_pattern_csr\n    elif source=='itsg': coeff_pattern=coeff_pattern_itsg\n    else: raise ValueError(\"Invalid source, pyshbundle only supports JPL, CSR, and ITSG\")\n\n\n    # Regular expression patterns to match the time coverage start and end lines\n    start_pattern = re.compile(r'time_coverage_start\\s*:\\s*([\\d\\-T:.]+)')\n    end_pattern = re.compile(r'time_coverage_end\\s*:\\s*([\\d\\-T:.]+)')\n    timeindex_itsg = re.compile(r'^modelname\\s+(.+)$')\n\n\n    # Open and read the gzipped file to extract the time coverage start and end dates\n    if source=='itsg':\n        with open(file_path, 'rt') as file:\n            for line in file:\n                # Strip any leading/trailing whitespace characters\n                line = line.strip()\n\n                # Search for time coverage start\n                start_match = timeindex_itsg.search(line)\n                if start_match:\n                    data['time_coverage_start'] = start_match.group(1)\n\n                # Break the loop if both dates are found\n                if data['time_coverage_start']:\n                    break\n            # File is automatically closed here due to the 'with' statement\n        with open(file_path, 'rt') as file:\n            for line in file:\n                # Strip any leading/trailing whitespace characters\n                line = line.strip()\n                # print(line)\n\n                # Search for the coefficient pattern in the line\n                coeff_match = coeff_pattern.search(line)\n                if coeff_match:\n                    # Extract degree, order, Clm, and Slm\n                    degree = int(coeff_match.group(1))\n                    order = int(coeff_match.group(2))\n                    clm = np.double(coeff_match.group(3))\n                    slm = np.double(coeff_match.group(4))\n                    clm_sdev = np.double(coeff_match.group(5))\n                    slm_sdev = np.double(coeff_match.group(6))\n\n                    # Store the coefficients in the dictionary\n                    data['coefficients'][(degree, order)] = {'Clm': clm, 'Slm': slm,\n                                                            'Clm_sdev': clm_sdev, 'Slm_sdev': slm_sdev}\n\n\n\n    elif source=='csr' or source=='jpl':\n        with gzip.open(file_path, 'rt') as file:   # gzip.open\n            for line in file:\n                # Strip any leading/trailing whitespace characters\n                line = line.strip()\n\n                # Search for time coverage start\n                start_match = start_pattern.search(line)\n                if start_match:\n                    data['time_coverage_start'] = start_match.group(1)\n\n                # Search for time coverage end\n                end_match = end_pattern.search(line)\n                if end_match:\n                    data['time_coverage_end'] = end_match.group(1)\n\n                # Break the loop if both dates are found\n                if data['time_coverage_start'] and data['time_coverage_end']:\n                    break\n            # File is automatically closed here due to the 'with' statement\n\n\n        # Open and read the gzipped file again to extract the coefficients\n        with gzip.open(file_path, 'rt') as file:\n            for line in file:\n                # Strip any leading/trailing whitespace characters\n                line = line.strip()\n                # print(line)\n\n                # Search for the coefficient pattern in the line\n                coeff_match = coeff_pattern.search(line)\n                if coeff_match:\n                    # Extract degree, order, Clm, and Slm\n                    degree = int(coeff_match.group(1))\n                    order = int(coeff_match.group(2))\n                    clm = np.double(coeff_match.group(3))\n                    slm = np.double(coeff_match.group(4))\n                    clm_sdev = np.double(coeff_match.group(5))\n                    slm_sdev = np.double(coeff_match.group(6))\n\n                    # Store the coefficients in the dictionary\n                    data['coefficients'][(degree, order)] = {'Clm': clm, 'Slm': slm,\n                                                            'Clm_sdev': clm_sdev, 'Slm_sdev': slm_sdev}\n    return data\n</code></pre>"},{"location":"load_data/#pyshbundle.io.extract_deg1_coeff_tn13","title":"<code>extract_deg1_coeff_tn13(file_path)</code>","text":"<p>Extracts the degree 1 coefficients from the given TN-13 file.</p> <p>Ensure the TN-13 file used is the one recommended by respective data centres (JPL, CSR, or ITSG). Similar to extract_SH_data, but specifically for TN-13 files. Returns degree 1 replacement coefficients as a dictionary. Uses the degree and order of a coefficient as the key and the coefficient values as the value.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Absolute path to the file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the degree 1 (order 1) coefficients and time coverage start and end dates.</p> Source code in <code>pyshbundle/io.py</code> <pre><code>def extract_deg1_coeff_tn13(file_path):\n    \"\"\"\n    Extracts the degree 1 coefficients from the given TN-13 file.\n\n    Ensure the TN-13 file used is the one recommended by respective data centres (JPL, CSR, or ITSG).\n    Similar to extract_SH_data, but specifically for TN-13 files.\n    Returns degree 1 replacement coefficients as a dictionary.\n    Uses the degree and order of a coefficient as the key and the coefficient values as the value.\n\n    Args:\n        file_path (str): Absolute path to the file.\n\n    Returns:\n        (dict): Dictionary containing the degree 1 (order 1) coefficients and time coverage start and end dates.\n    \"\"\"\n\n    data_dict = {}\n\n    with open(file_path, 'rt') as file:\n        lines = file.readlines()\n        for line in lines:\n\n            # Extract data using regex\n            pattern = re.compile(r'^GRCOF2\\s+(\\d+)\\s+(\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+([-+]?\\d*\\.\\d+e[-+]?\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)')\n            match = pattern.match(line)\n\n            if match:\n                degree = int(match.group(1))\n                order = int(match.group(2))\n                Clm = float(match.group(3))\n                Slm = float(match.group(4))\n                Clm_sdev = np.double(match.group(5))\n                Slm_sdev = np.double(match.group(6))\n                epoch_begin = match.group(7)\n                epoch_end = match.group(8)\n\n                # Use epoch start as key but in yyyy-mm-dd format\n                epoch_key=datetime.strptime(epoch_begin, '%Y%m%d.%H%M%S').strftime('%Y-%m')\n                data_dict[epoch_key, degree, order] = {\n                    'degree': degree,\n                    'order': order,\n                    'Clm': Clm,\n                    'Slm': Slm,\n                    'Clm_sdev': Clm_sdev,\n                    'Slm_sdev': Slm_sdev,\n                    'epoch_begin': epoch_begin,\n                    'epoch_end': epoch_end,\n                }\n    # Print a sample of the data to check if it's parsed correctly\n    # for key in sorted(data_dict.keys())[:5]:  # print first 5 entries\n    #     print(f\"{key}: {data_dict[key]}\")\n    return data_dict\n</code></pre>"},{"location":"load_data/#pyshbundle.io.extract_deg2_3_coeff_tn14","title":"<code>extract_deg2_3_coeff_tn14(file_path)</code>","text":"<p>Extracts the degree 2 and 3 coefficients from the given file.</p> <p>Ensure the TN-14 file used is the one recommended by respective data centres (JPL, CSR, or ITSG). Similar to extract_SH_data, but specifically for TN-14 files. Returns degree 2, 3 replacement coefficients as a dictionary. Uses the degree and order of a coefficient as the key and the coefficient values as the value.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Absolute path to the file.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the degree 2, 3 (order 0) coefficients and time coverage start and end dates.</p> Source code in <code>pyshbundle/io.py</code> <pre><code>def extract_deg2_3_coeff_tn14(file_path):\n    \"\"\"\n    Extracts the degree 2 and 3 coefficients from the given file.\n\n    Ensure the TN-14 file used is the one recommended by respective data centres (JPL, CSR, or ITSG).\n    Similar to extract_SH_data, but specifically for TN-14 files.\n    Returns degree 2, 3 replacement coefficients as a dictionary.\n    Uses the degree and order of a coefficient as the key and the coefficient values as the value.\n\n    Args:\n        file_path (str): Absolute path to the file.\n\n    Returns:\n        (dict): Dictionary containing the degree 2, 3 (order 0) coefficients and time coverage start and end dates.\n    \"\"\"\n    data_dict = {}\n\n    with open(file_path, 'rt') as file:\n        lines = file.readlines()\n        for line in lines:\n\n            # Extract data using regex\n            pattern = re.compile(\n                r'(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+([-\\d.eE+]+)\\s+([-\\d.eE+]+)\\s+([-\\d.eE+]+)\\s+([-\\d.eE+]+|NaN)?\\s+([-\\d.eE+]+|NaN)?\\s+([-\\d.eE+]+|NaN)?\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)')\n            match = pattern.match(line)\n\n            if match:\n                mjd_start = float(match.group(1))\n                year_frac_start = float(match.group(2))\n                c20 = np.double(match.group(3))\n                c20_mean_diff = np.double(match.group(4))\n                c20_sigma = np.double(match.group(5))\n                c30 = match.group(6)\n                c30_mean_diff = match.group(7)\n                c30_sigma = match.group(8)\n                mjd_end = float(match.group(9))\n                year_frac_end = float(match.group(10))\n\n                # Only add C30 if it exists (not)\n                if c30.lower() != 'nan':\n                    c30 = np.double(c30)\n                    c30_mean_diff = np.double(c30_mean_diff)\n                    c30_sigma = np.double(c30_sigma)\n                else:\n                    c30 = None\n                    c30_mean_diff = None\n                    c30_sigma = None\n\n                # Use mjd as key but in yyyy-mm-dd format\n                mjd_key = julian.from_jd(mjd_start, fmt='mjd').date().strftime('%Y-%m')\n                data_dict[mjd_key] = {\n                    'year_frac_start': year_frac_start,\n                    'mjd_start': mjd_start,\n                    'c20': c20,\n                    'c20_mean_diff': c20_mean_diff,\n                    'c20_sigma': c20_sigma,\n                    'c30': c30,\n                    'c30_mean_diff': c30_mean_diff,\n                    'c30_sigma': c30_sigma,\n                    'mjd_end': mjd_end,\n                    'year_frac_end': year_frac_end\n                }\n    # Print a sample of the data to check if it's parsed correctly\n    # for key in sorted(data_dict.keys())[:5]:  # print first 5 entries\n    #     print(f\"{key}: {data_dict[key]}\")\n    return data_dict\n</code></pre>"},{"location":"load_data/#pyshbundle.io.load_longterm_mean","title":"<code>load_longterm_mean(source='', use_sample_mean=0)</code>","text":"<p>Loads the long term mean values for the GRACE SH data.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Source of data. Defaults to \"\".</p> <code>''</code> <code>use_sample_mean</code> <code>int</code> <p>Whether to use default long-mean values provided with the data. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the source selection is incorrect.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>Path of the appropriate long term mean file.</p> Todo <ul> <li>Not sure if using \"source = ''\" is all right.</li> <li>Instead of base exception, it can be ValueError.</li> </ul> Source code in <code>pyshbundle/io.py</code> <pre><code>def load_longterm_mean(source = \"\", use_sample_mean = 0):\n    \"\"\"\n    Loads the long term mean values for the GRACE SH data.\n\n    Args:\n        source (str, optional): Source of data. Defaults to \"\".\n        use_sample_mean (int, optional): Whether to use default long-mean values provided with the data. Defaults to 0.\n\n    Raises:\n        ValueError: If the source selection is incorrect.\n\n    Returns:\n        str: Path of the appropriate long term mean file.\n\n    Todo:\n        + Not sure if using \"source = ''\" is all right.\n        + Instead of base exception, it can be ValueError.\n    \"\"\"\n# @author: Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n\n    if use_sample_mean == 1:\n        print(\"Loading preloaded RL06 long term mean values\")\n        print(\"Please ensure that your data is RL06 \\nIf not, please manually input long term mean by setting use_sample_mean = 0\")\n\n        if str.upper(source) == 'CSR':\n            long_mean = pkg_resources.resource_filename('pyshbundle', 'data/RL06_long_mean/SH_long_mean_csr.npy')\n        elif str.upper(source) == 'JPL':\n            long_mean = pkg_resources.resource_filename('pyshbundle', 'data/RL06_long_mean/SH_long_mean_itsg.npy')\n        elif str.upper(source) == 'ITSG':\n            long_mean = pkg_resources.resource_filename('pyshbundle', 'data/RL06_long_mean/SH_long_mean_jpl.npy')\n        else:\n            raise Exception(\"Incorrect selection of source\")\n        print(\"Successfully loaded preloaded longterm means\")\n    else:\n        print(\"Please download and provide the longterm GRACE SH mean values\")\n        print(\"Instructions to download the longterm GRACE SH mean values may be referred to in https://github.com/mn5hk/pyshbundle/blob/main/docs/index.md#how-to-download-data\")\n        long_mean = str(input(\"Enter the longterm mean for the SH values in the numpy (.npy) format\"))\n        print(\"Successfully loaded path to long term mean:\", long_mean)\n\n    return long_mean\n</code></pre>"},{"location":"load_data/#pyshbundle.io.parse_jpl_file","title":"<code>parse_jpl_file(file_path)</code>","text":"<p>Reads the spherical harmonic data provided by JPL.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Absolute path to the file.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing: - jpl_header (dict): Parsed header information. - jpl_data (dict): Extracted spherical harmonic coefficients data.</p> Source code in <code>pyshbundle/io.py</code> <pre><code>def parse_jpl_file(file_path: str):\n    \"\"\"\n    Reads the spherical harmonic data provided by JPL.\n\n    Args:\n        file_path (str): Absolute path to the file.\n\n    Returns:\n        tuple: A tuple containing:\n            - jpl_header (dict): Parsed header information.\n            - jpl_data (dict): Extracted spherical harmonic coefficients data.\n    \"\"\"\n    # ensure that the file path is valid then proceed\n\n    source = 'JPL'\n\n    # check if the file is ziped or not\n\n    if file_path[-3:] == '.gz':\n        # open the file and read the lines\n        with gzip.open(file_path, 'r') as file:\n\n            # read the file line wise -&gt; obtain a list of bytes\n            info_lines = file.readlines()\n            num_lines = len(info_lines)\n\n            for i in range(len(info_lines)):\n                # find the end of header sentence in the text file\n                if str(info_lines[i]) == str(b'# End of YAML header\\n',):\n                    end_of_header_idx = i\n                    break\n\n        # everything after the header is the numerical data    \n        header_info = info_lines[:end_of_header_idx]\n\n        # parse the header strings to extract relavant metadata info\n        jpl_header = parse_jpl_header(header_info)\n\n        # parse the header strings to extract relavant metadata info\n        jpl_data = extract_SH_data(file_path, source='itsg')\n\n    return jpl_header, jpl_data\n</code></pre>"},{"location":"load_data/#pyshbundle.io.read_GRACE_SH_paths","title":"<code>read_GRACE_SH_paths(use_sample_files=0)</code>","text":"<p>Returns path of data files, path of tn13 and path of tn14 replacement files.</p> <p>Parameters:</p> Name Type Description Default <code>use_sample_files</code> <code>int</code> <p>Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If the source selection is incorrect.</p> <p>Returns:</p> Name Type Description <code>tuple</code> <ul> <li>path_sh (str): Path of data files.</li> <li>path_tn13 (str): Path of tn13 replacement file.</li> <li>path_tn14 (str): Path of tn14 replacement file.</li> <li>source (str): Source of the SH files (JPL, ITSG, or CSR).</li> </ul> Remarks <p>The purpose of this script is to: - Read what the data source is (JPL, CSR, or ITSG). - Read file path for GRACE L2 spherical harmonics inputs. - Read replacement files for tn13 and tn14. - Identify the source of the SH files (JPL, ITSG, or CSR).</p> Source code in <code>pyshbundle/io.py</code> <pre><code>def read_GRACE_SH_paths(use_sample_files = 0):\n    \"\"\"\n    Returns path of data files, path of tn13 and path of tn14 replacement files.\n\n    Args:\n        use_sample_files (int, optional): Defaults to 0.\n\n    Raises:\n        Exception: If the source selection is incorrect.\n\n    Returns:\n        tuple: \n            - path_sh (str): Path of data files.\n            - path_tn13 (str): Path of tn13 replacement file.\n            - path_tn14 (str): Path of tn14 replacement file.\n            - source (str): Source of the SH files (JPL, ITSG, or CSR).\n\n    Remarks:\n        The purpose of this script is to:\n        - Read what the data source is (JPL, CSR, or ITSG).\n        - Read file path for GRACE L2 spherical harmonics inputs.\n        - Read replacement files for tn13 and tn14.\n        - Identify the source of the SH files (JPL, ITSG, or CSR).\n    \"\"\"\n    #Created on Fri Feb  17 2023\n    #@author: Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n\n    print(\"This program supports working with GRACE L2 Spherical harmonics data from the following centers: CSR, JPL and ITSG\")\n    print(\"Instructions to download data may be referred to in https://github.com/mn5hk/pyshbundle/blob/main/docs/index.md#how-to-download-data\")\n    source = str(input(\"Enter the source of L2 SH coeffs code(jpl, csr, gfz): \"))\n\n    if use_sample_files ==1:\n\n        print(\"You have chosen to use sample replacement files.\")\n        print(\"The replacement files for the TN13 and TN14 Args have been preloaded into the program\")\n        print(\"Due to the size of the GRACE SH files, these have not been preloaded into the program\")\n        print(\"You may download the GRACE SH L2 files from the link below. Please ensure to download the files as per your selection of source in the prior step\")\n        print(\"Download sample files from: https://github.com/mn5hk/pyshbundle/tree/main/sample_input_data\")\n    path_sh = str(input(\"Enter the path to the folder with SH L2 data\"))\n\n\n    if str.upper(source) == 'JPL':\n        if use_sample_files == 1:\n            path_tn13 = pkg_resources.resource_filename('pyshbundle', 'data/sample_JPL_TN_files/TN-13_GEOC_JPL_RL06.txt')\n            path_tn14 = pkg_resources.resource_filename('pyshbundle', 'data/sample_JPL_TN_files/TN-14_C30_C20_GSFC_SLR.txt')\n            print(\"Successfully loaded preloaded TN13 and TN14 replacement files for JPL\")\n        else:\n            path_tn13 = str(input(\"Enter the path to the file for tn13 replacement in .txt format\"))\n            path_tn14 = str(input(\"Enter the path to the file for tn14 replacement in .txt format\"))\n            print(\"Successfully loaded TN13 and TN14 replacement files for JPL\")\n\n    elif str.upper(source) == 'CSR':\n        if use_sample_files == 1:\n            path_tn13 = pkg_resources.resource_filename('pyshbundle', 'data/sample_CSR_TN_files/TN-14_C30_C20_SLR_GSFC.txt')\n            path_tn14 = pkg_resources.resource_filename('pyshbundle', 'data/sample_CSR_TN_files/TN-13_GEOC_CSR_RL06.1.txt')\n            print(\"Successfully loaded preloaded TN13 and TN14 replacement files for CSR\")\n        else:\n            path_tn13 = str(input(\"Enter the path to the file for tn13 replacement in .txt format\"))\n            path_tn14 = str(input(\"Enter the path to the file for tn14 replacement in .txt format\"))\n            print(\"Successfully loaded TN13 and TN14 replacement files for CSR\")\n\n    elif str.upper(source) == 'ITSG':\n        if use_sample_files == 1:\n            path_tn13 = pkg_resources.resource_filename('pyshbundle', 'data/sample_ITSG_TN_files/TN-13_GEOC_CSR_RL06.1.txt')\n            path_tn14 = pkg_resources.resource_filename('pyshbundle', 'data/sample_ITSG_TN_files/TN-14_C30_C20_SLR_GSFC.txt')\n            print(\"Successfully loaded preloaded TN13 and TN14 replacement files for ITSG\")\n        else:\n            path_tn13 = str(input(\"Enter the path to the file for tn13 replacement in .txt format\"))\n            path_tn14 = str(input(\"Enter the path to the file for tn14 replacement in .txt format\"))\n            print(\"Successfully loaded TN13 and TN14 replacement files for ITSG\")\n    else:\n        raise Exception(\"Source selection is incorrect. Please select between JPL, CSR or gfz\")\n\n    return path_sh, path_tn13, path_tn14, source\n</code></pre>"},{"location":"load_data/#pyshbundle.io.replace_zonal_coeff","title":"<code>replace_zonal_coeff(data_mat, source, lmax, data_tn13, data_tn14, epoch_begin, epoch_end)</code>","text":"<p>Replaces the zonal coefficients in the given data matrix with the replacement coefficients  from the provided TN-13 and TN-14 data.</p> <p>Parameters:</p> Name Type Description Default <code>data_mat</code> <code>ndarray</code> <p>The original data matrix containing spherical harmonic coefficients.</p> required <code>source</code> <code>str</code> <p>The source of the data ('jpl', 'csr', or 'itsg').</p> required <code>lmax</code> <code>int</code> <p>The maximum degree of the spherical harmonic expansion.</p> required <code>data_tn13</code> <code>ndarray</code> <p>The TN-13 replacement coefficients data.</p> required <code>data_tn14</code> <code>ndarray</code> <p>The TN-14 replacement coefficients data.</p> required <code>epoch_begin</code> <code>float</code> <p>The start date of the epoch in YYYYMMDD format.</p> required <code>epoch_end</code> <code>float</code> <p>The end date of the epoch in YYYYMMDD format. Defaults to None.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>The data matrix with the zonal coefficients replaced.</p> Source code in <code>pyshbundle/io.py</code> <pre><code>def replace_zonal_coeff(data_mat, source, lmax, data_tn13, data_tn14, epoch_begin: float, epoch_end: float):\n    \"\"\"\n    Replaces the zonal coefficients in the given data matrix with the replacement coefficients \n    from the provided TN-13 and TN-14 data.\n\n    Args:\n        data_mat (numpy.ndarray): The original data matrix containing spherical harmonic coefficients.\n        source (str): The source of the data ('jpl', 'csr', or 'itsg').\n        lmax (int): The maximum degree of the spherical harmonic expansion.\n        data_tn13 (numpy.ndarray): The TN-13 replacement coefficients data.\n        data_tn14 (numpy.ndarray): The TN-14 replacement coefficients data.\n        epoch_begin (float): The start date of the epoch in YYYYMMDD format.\n        epoch_end (float, optional): The end date of the epoch in YYYYMMDD format. Defaults to None.\n\n    Returns:\n        (numpy.ndarray): The data matrix with the zonal coefficients replaced.\n    \"\"\"\n\n    data_mat_copy = deepcopy(data_mat)\n\n    if source == 'jpl':\n        assert epoch_end is not None, \"epoch_end argument cannot be None\"\n        # convert the float YYYYMMDD into datetime.date object\n        epoch_begin = datetime.strptime(str(int(epoch_begin)), '%Y%m%d').date()\n        epoch_end = datetime.strptime(str(int(epoch_end)), '%Y%m%d').date()\n\n        # Extract the C10, C11, C20 and C30 from TN-13 and TN-14\n        C10, C11 = extract_C10_11_replcmnt_coeff(\n            data_tn13, 'jpl', epoch_begin, epoch_end)\n        C20 = extract_C20_replcmnt_coeff(\n            data_tn14, source, epoch_begin, epoch_end)\n        C30 = extract_C30_replcmnt_coeff(\n            data_tn14, source, epoch_begin, epoch_end)\n\n        # For easy replacement purpose\n        # [l, m, clm, slm, clm_dev, slm_dev]\n        C00 = np.array([0, 0, 0, 0, 0, 0])\n\n        # C30 is  at index - 3 in original matrix\n        if C30 is not None:\n            data_mat_copy[3, :] = C30\n\n        # C20 is at index - 0 in original matrix\n        data_mat_copy[0, :] = C20\n\n        # stack the matrix row-wise\n        data_mat_copy = np.row_stack([C11, data_mat_copy])\n        data_mat_copy = np.row_stack([C10, data_mat_copy])\n        data_mat_copy = np.row_stack([C00, data_mat_copy])\n\n    elif source == 'csr':\n        epoch_begin = datetime.strptime(str(int(epoch_begin)), '%Y%m%d').date()\n        epoch_end = datetime.strptime(str(int(epoch_end)), '%Y%m%d').date()\n\n        C10, C11 = extract_C10_11_replcmnt_coeff(\n            data_tn13, 'csr', epoch_begin, epoch_end)\n\n        C20 = extract_C20_replcmnt_coeff(\n            data_tn14, 'csr', epoch_begin, epoch_end)\n        C30 = extract_C30_replcmnt_coeff(\n            data_tn14, 'csr', epoch_begin, epoch_end)\n\n        # C10 is at index - 1\n        # C20 is at index - 2\n        # C30 is at index - 3\n        # C11 is at index - lmax + 1\n        data_mat_copy[lmax+1, :] = C11\n        if C30 is not None:\n            data_mat_copy[3, :] = C30        \n        data_mat_copy[2, :] = C20\n        data_mat_copy[1, :] = C10\n\n    elif source == 'itsg':\n        # the CSR dates are strings to begin with\n        begin_date = datetime.strptime((epoch_begin), '%Y-%m').date()\n\n        C10, C11 = extract_C10_11_replcmnt_coeff(\n            data_tn13, 'itsg', epoch_begin=begin_date, epoch_end=None)\n\n        print(C10, C11)\n\n        C20 = extract_C20_replcmnt_coeff(\n            data_tn14, 'itsg', epoch_begin=begin_date, epoch_end=None)\n        C30 = extract_C30_replcmnt_coeff(\n            data_tn14, 'itsg', epoch_begin=begin_date, epoch_end=None)\n\n        # For easy replacement purpose\n        # C10 is at index 1\n        # C11 is at index 2\n        # C20 is at index 3\n        # C30 is at index 6\n        if C30 is not None:\n            data_mat_copy[6, :] = C30\n        data_mat_copy[3, :] = C20\n        data_mat_copy[2, :] = C11\n        data_mat_copy[1, :] = C10\n\n    return data_mat_copy\n</code></pre>"},{"location":"load_data/#pyshbundle.io.sub2ind","title":"<code>sub2ind(array_shape, rows, cols)</code>","text":"<p>Convert row and column subscripts to linear indices.</p> <p>Parameters:</p> Name Type Description Default <code>array_shape</code> <code>tuple</code> <p>Shape of the array as a tuple (num_rows, num_cols).</p> required <code>rows</code> <code>int or array - like</code> <p>Row indices.</p> required <code>cols</code> <code>int or array - like</code> <p>Column indices.</p> required <p>Returns:</p> Type Description <p>int or array-like: Linear indices corresponding to the row and column subscripts.</p> Source code in <code>pyshbundle/io.py</code> <pre><code>def sub2ind(array_shape, rows, cols):\n    \"\"\"\n    Convert row and column subscripts to linear indices.\n\n    Args:\n        array_shape (tuple): Shape of the array as a tuple (num_rows, num_cols).\n        rows (int or array-like): Row indices.\n        cols (int or array-like): Column indices.\n\n    Returns:\n        int or array-like: Linear indices corresponding to the row and column subscripts.\n    \"\"\"\n    # rows, list need to be linear array\n    return rows*array_shape[1] + cols\n</code></pre>"},{"location":"load_data/#computing-long-term-mean","title":"Computing Long Term Mean","text":"<p>Loads the long term mean values for the GRACE SH data.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Source of data. Defaults to \"\".</p> <code>''</code> <code>use_sample_mean</code> <code>int</code> <p>Whether to use default long-mean values provided with the data. Defaults to 0.</p> <code>0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the source selection is incorrect.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>Path of the appropriate long term mean file.</p> Todo <ul> <li>Not sure if using \"source = ''\" is all right.</li> <li>Instead of base exception, it can be ValueError.</li> </ul> Source code in <code>pyshbundle/io.py</code> <pre><code>def load_longterm_mean(source = \"\", use_sample_mean = 0):\n    \"\"\"\n    Loads the long term mean values for the GRACE SH data.\n\n    Args:\n        source (str, optional): Source of data. Defaults to \"\".\n        use_sample_mean (int, optional): Whether to use default long-mean values provided with the data. Defaults to 0.\n\n    Raises:\n        ValueError: If the source selection is incorrect.\n\n    Returns:\n        str: Path of the appropriate long term mean file.\n\n    Todo:\n        + Not sure if using \"source = ''\" is all right.\n        + Instead of base exception, it can be ValueError.\n    \"\"\"\n# @author: Amin Shakya, Interdisciplinary Center for Water Research (ICWaR), Indian Institute of Science (IISc)\n\n    if use_sample_mean == 1:\n        print(\"Loading preloaded RL06 long term mean values\")\n        print(\"Please ensure that your data is RL06 \\nIf not, please manually input long term mean by setting use_sample_mean = 0\")\n\n        if str.upper(source) == 'CSR':\n            long_mean = pkg_resources.resource_filename('pyshbundle', 'data/RL06_long_mean/SH_long_mean_csr.npy')\n        elif str.upper(source) == 'JPL':\n            long_mean = pkg_resources.resource_filename('pyshbundle', 'data/RL06_long_mean/SH_long_mean_itsg.npy')\n        elif str.upper(source) == 'ITSG':\n            long_mean = pkg_resources.resource_filename('pyshbundle', 'data/RL06_long_mean/SH_long_mean_jpl.npy')\n        else:\n            raise Exception(\"Incorrect selection of source\")\n        print(\"Successfully loaded preloaded longterm means\")\n    else:\n        print(\"Please download and provide the longterm GRACE SH mean values\")\n        print(\"Instructions to download the longterm GRACE SH mean values may be referred to in https://github.com/mn5hk/pyshbundle/blob/main/docs/index.md#how-to-download-data\")\n        long_mean = str(input(\"Enter the longterm mean for the SH values in the numpy (.npy) format\"))\n        print(\"Successfully loaded path to long term mean:\", long_mean)\n\n    return long_mean\n</code></pre>"},{"location":"load_data/#physical-and-geodetic-constants","title":"Physical and Geodetic Constants","text":"<p>This script contains some of the major relavant Physical and Geodetic(GRS80) constants:</p> <ul> <li><code>clight</code> speed of light - \\(2.99792458e+8\\) \\(m/s\\)</li> <li><code>G</code> Gravitational constant- \\(6.67259e-11\\) $\frac{m^3} {kg \\cdot s^2}$</li> <li> <p><code>au</code> astronomical unit - \\(149.597870691e+9\\) \\(m\\)</p> </li> <li> <p><code>ae</code> semi-major axis of ellipsoid <code>GRS 80</code>- \\(6378137\\) m</p> </li> <li><code>GM</code> geocentric grav. constant <code>GRS 80</code>- \\(3.986005e+14\\) $\frac{m^3}{s^2}$</li> <li><code>J2</code> earth's dynamic form factor <code>GRS 80</code> - \\(1.08263e-3\\) [unitless C20 unnormalized coefficient]</li> <li> <p><code>Omega</code> mean ang. velocity <code>GRS 80</code> - $7.292115e-5 $\frac{rad}{s}$</p> </li> <li> <p><code>flat</code> flattening - $\frac{1}{298.257222101}$</p> </li> </ul>"},{"location":"pyshbundle/","title":"Reference Mannual - PySHBundle","text":"<p>The module codes can be categorized into four categories:</p> <ul> <li>Load Data Modules</li> <li>Convert data formats</li> <li>Core functionality</li> <li>Auxillary codes</li> </ul> <p></p> <p>Navigate the Reference Manual based on the following schematic</p>"},{"location":"theory/","title":"Theoretical Background","text":""},{"location":"theory/#mathematics","title":"Mathematics","text":"<p>In this section, we present a mathematical representation of the spherical harmonics analysis. According to potential theory, the gravitational field of a body fulfils the Laplace equation \\(\\nabla^2\\phi = 0\\). Laplace's equation in spherical coordinates can be written as follows: </p> \\[\\begin{equation}     \\frac{1}{r^2}\\frac{\\partial}{\\partial r}\\bigg( r^2\\frac{\\partial \\phi}{\\partial r}\\bigg)       +     \\frac{1}{r^2\\sin\\vartheta}\\frac{\\partial}{\\partial \\vartheta}\\bigg(\\sin\\vartheta\\frac{\\partial \\phi}{\\partial \\vartheta}\\bigg)      +     \\frac{1}{r^2\\sin^2\\vartheta}\\frac{\\partial^2 \\phi}{\\partial \\lambda^2}     = 0 , \\end{equation}\\] <p>where  \\(\\phi\\) is the potential,  \\(r\\) is the radius,  \\(\\vartheta\\) is the co-latitude and  \\(\\lambda\\) is the longitude. </p> <p>We perform a separation of variables and insert \\(\\phi(r, \\vartheta, \\lambda) =f(r)g(\\vartheta)h(\\lambda)\\) into the Laplace equation to get three independent equations:</p> \\[\\begin{equation} r^2\\frac{d^2f}{dr^2}+2r\\frac{df}{dr} - n(n+1)f = 0, \\end{equation}\\] \\[\\begin{equation} \\frac{d^2g}{d\\vartheta^2} + \\frac{dg}{d\\vartheta}\\cot\\vartheta + \\bigg(  n(n+1) - \\frac{m^2}{\\sin^2\\vartheta}   \\bigg) g = 0 , \\end{equation}\\] \\[\\begin{equation} \\frac{d^2h}{d\\lambda^2} + m^2h = 0, \\end{equation}\\] <p>where \\(m\\) and \\(n\\) are the degree and order respectively. Solving \\((2), (3)\\) and \\((4)\\), we obtain: </p> \\[\\begin{equation} f(r) \\in \\{r^n, r^{-(n+1)}\\}, \\end{equation}\\] \\[\\begin{equation} g(\\vartheta) \\in \\{P_{n,m}(\\cos \\vartheta), Q_{n,m}(\\cos \\vartheta)\\} , \\end{equation}\\] <p>\\begin{equation} h(\\lambda) \\in {\\cos m\\lambda, \\sin m\\lambda}. \\end{equation}\\</p> <p>Thus, the Laplace equation's solution takes the following form: </p> \\[\\begin{equation} \\phi(r, \\vartheta, \\lambda) = \\sum_{n=0}^{\\infty} \\sum_{m=0}^{n}  \\alpha_{n,m} \\begin{Bmatrix} P_{n,m}(\\cos\\vartheta)\\\\ Q_{n,m}(\\cos\\vartheta)\\\\ \\end{Bmatrix} \\dot{\u2022} \\begin{Bmatrix} \\cos m\\lambda\\\\ \\sin m\\lambda\\\\ \\end{Bmatrix} \\dot{\u2022} \\begin{Bmatrix} r^n\\\\ r^{(n+1)}\\\\ \\end{Bmatrix} . \\end{equation}\\] <p>Solutions for \\(f(r)\\) and \\(h(\\lambda)\\) are fairly straightforward. Eq - (3) for \\(g(\\vartheta)\\) is in the form of a Legendre differential equation and its solutions are \\(P_{n,m}(\\cos \\vartheta)\\) and \\(Q_{n,m}(\\cos \\vartheta)\\), the associated Legendre functions of the first and second kind. We now apply two constraints to the solution:</p> <ul> <li>\\(\\phi \\rightarrow 0\\) when \\(r \\rightarrow \\infty\\),</li> <li>\\(\\phi\\) is limited on the sphere,</li> </ul> <p>which leads us to eliminate \\(Q_{n,m}(\\cos \\vartheta)\\) and \\(r^n\\).The \\(4\\pi\\) normalization of the Associated Legendre functions [8] is utilized in our package and is given by: </p> \\[\\begin{equation} \\bar{P}_{n,m}(\\cos\\vartheta) = P_{n,m}(\\cos\\vartheta)\\sqrt{(2-\\delta_{m0})(2n+1)\\frac{(n-m)!}{(n+m)!}}, \\end{equation}\\] <p>where \\(\\delta_{m0}\\) is the Kronecker delta function,</p> \\[\\begin{equation} P_{n,m}(t) = (1-t^2)^{\\frac{m}{2}}\\frac{d^mP_n(t)}{dt^m}, \\end{equation}\\] <p>and </p> \\[\\begin{equation} nP_n(t)=-(n-1)P_{n-2}(t) + (2n-1)tP_{n-1}(t). \\end{equation}\\] <p>Spherical harmonics are the angular portion of a set of solutions to Laplace's equation. They take into account \\(\\vartheta\\) and \\(\\lambda\\). They are functions modelled on the surface of a sphere, denoted by \\(Y_{n,m}(\\vartheta,\\lambda)\\). They are of three kinds: </p> <ul> <li>Zonal harmonics: \\(m=0\\) - they are only latitude dependent,</li> <li>Tesseral harmonics: \\(0 &lt; m &lt; n\\), and </li> <li>Sectorial harmonics: \\(m=n\\).</li> </ul> <p>Quantities like the gravitational potential, height of water column, gravity anomaly and so on are the functionals of the gravity field which are obtained by differentiating the potential \\(\\phi\\) with respect to the spherical coordinates. </p> <p>The gravitational potential anomaly \\(V\\) is given by:</p> \\[\\begin{equation}     V(r, \\vartheta, \\lambda) =      \\frac{GM}{r} \\sum_{n=0} ^{N_{max}} \\sum_{m=0} ^{n}      \\left(\\frac{R}{r}\\right) ^{n+1}     \\bar{P}_{n,m}(\\cos \\vartheta) [C_{n,m}\\cos m\\lambda+S_{n,m}\\sin m\\lambda]. \\end{equation}\\] <p>Here, \\(R\\) refers to the radius of the Earth, \\(\\bar{P}_ {n,m}\\) refers to the Associated Legendre functions with \\(4\\pi\\) normalization, \\(C_{lm}\\) and  \\(S_{lm}\\) refer to the spherical harmonic coefficients. Similarly, another functional, the change in surface mass density, is represented by:</p> \\[\\begin{equation}     \\Delta\\sigma(\\vartheta, \\lambda) =      \\frac{a\\rho_{ave}}{3}      \\sum_{n=0}^{N_{max}}\\sum_{m=0}^{n}      \\left(\\frac{R}{r}\\right)^{n+1}      \\bar{P}_{n,m}(\\cos\\vartheta)     \\frac{2n+1}{1+k_l}     [C_{n,m}\\cos m\\lambda + S_{n,m}\\sin m\\lambda], \\end{equation}\\] <p>where \\(\\rho_{ave}\\) refers to the average density of the Earth in \\(g/cm^3\\) and \\(k_n\\) refers to the load Love number of degree \\(n\\).</p>"},{"location":"theory/#grace-data-levels","title":"GRACE Data Levels","text":"<p>The <code>GRACE</code> data products are being developed, processed  and archieved in a shared Science Data System between the <code>Jet Propulsion Laboratory(JPL)</code>, the <code>University of Texas Center for Space Research (UT-CSR)</code> and <code>GeoForschungsZentrum Potsdam (GFZ)</code>.</p> <ul> <li> <p>Level 0:     The level-0 data are the result of the data reception, collection and decommutation by the Raw Data Center (RDC) of the Mission Operation System (MOS) located in Neustrelitz, Germany. The MOS receives twice per day using its Weilheim and Neustrelitz tracking antennae the science instrument and housekeeping data from each GRACE satellite which will be stored in two appropriate files in the level-0 rolling archive at DFD/Neustrelitz. The SDS retrieves these files and extracts and reformats the orresponding instrument and ancillary housekeeping data like GPS navigation solutions,space segment temperatures or thruster firing events. Level-0 products are available 24-hours after data reception.</p> </li> <li> <p>Level 1:     The level-1 data are the preprocessed, time-tagged and normal-pointed instrument data. These are the K-band ranging, accelerometer, star camera and GPS data of both satellites. Additionally the preliminary orbits of both GRACE satellites will be generated. Level-1 data processing software is developed by JPL with support from GFZ (e.g. accelerometer data preprocessing). Processing of level-1 products is done primarily at JPL. An identical processing system (hardware/software) is installed at GFZ to serve as a backup system in case of hardware or network problems. This double implementation is necessary to guarantee the envisaged level-1 product delay of 5 days. All level-1 products are archived at JPL\u2019s Physical Oceanography Distributed Active Data Center(PODAAC) and at GFZ\u2019s Integrated System Data Center (ISDC) . Both archives are harmonized on a sub-daily timeframe.</p> </li> <li> <p>Level 2: <code>Spherical Harmonic Coefficients</code> for the geopotential</p> <p>Level-2 data include the short term (30 days) and mean gravity field derived from calibrated and validated GRACE level-1 data products. This level also includes ancillary data sets (temperature and pressure fields, ocean bottom pressure, and hydrological data) which are necessary to eliminate time variabilities in gravity field solutions. Additionally the precise orbits of both GRACE satellites are generated. All level-2 products are archived at JPL\u2019s PODAAC and at GFZs ISDC and are available 60 days after data taking. The level-2 processing software were developed independently by all three processing centres using already existing but completely independent software packages which were upgraded for GRACE specific tasks. Common data file interfaces guarantees a strong product validation. Routine processing is done at UTCSR and GFZ, while JPL only generate level-2 products at times for verification purposes.</p> </li> <li> <p>Level 3: <code>Mascons</code>     consists of mass anomalies or other standardized products such as Monthly Ocean/Land Water Equivalent Thickness, Surface-Mass Anomaly. Similarly mass concentration blocks or <code>mascons</code> are also available.</p> </li> <li> <p>Level 4: <code>Time Series</code>     Time-series of catchment level hydrological estimates of TWSA</p> </li> </ul> <p><code>PySHBundle</code> provides the capability to obtain grided Total Water Storage Anomaly(TWSA) from Level 2 data.</p> <p>Spherical harmonic functions or coefficients, Legendre functions and their derivatives can be arranged in different ways. There are multiple functions in SHBundle for reordering from one format to another. Some of them have been translated to Python in PySHBundle. Couple of new ones have also been added.</p>"},{"location":"theory/#spherical-harmonics-data-formats","title":"Spherical Harmonics Data Formats","text":""},{"location":"theory/#clm-format","title":"clm-format","text":"<p>This is a standard format to store spherical harmonic coefficients in the indexed column-vector-format (abbreviatedL clm-format)</p> \\[\\begin{equation}   \\left( n, m, \\overline{C}_{n, m}, \\overline{S}_{n, m}, \\left[ \\sigma_{\\overline{C}_{n, m}}, \\sigma_{\\overline{S}_{n, m}} \\right] \\right) \\end{equation}\\] <p>The first column represents the degree \\(n\\), the second column represents the order \\(m\\) (both n,m are integers), followed by the coefficients \\(\\overline{C}_{n, m}, \\overline{S}_{n, m}\\) and the last two columns contain their respective standard deviations \\(\\sigma_{\\overline{C}_{n, m}}, \\sigma_{\\overline{S}_{n, m}}\\)</p>"},{"location":"theory/#klm-format","title":"klm-format","text":"<p>This is a variation of the clm-format for compact notation with just 3 or 4 columns. The coefficients are sorted first w.r.t. degree and then the order, particularly the sine-coefficients are arranged starting first with negative orders. The following matrix represents the klm-format:</p> \\[\\begin{bmatrix}     0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\     0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\     0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\      0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\      0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\      0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\      0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\      0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\     0 &amp; 0 &amp; \\overline{C}_{0, 0} &amp; \\sigma_{\\overline{C}_{0, 0}} \\\\      \\vdots &amp; &amp; &amp; \\vdots \\\\ N_{max} &amp; N_{max} &amp; \\overline{C}_{N_{max}, N_{max}} &amp; \\sigma_{\\overline{C}_{N_max}, N_{max}} \\\\  \\end{bmatrix}\\]"},{"location":"theory/#left-c-backslash-s-right-format","title":"\\(\\left | C \\backslash S \\right |\\) format","text":"<p>This is another well known arrangement of Spherical Harmonic coefficients. This is a square matrix of size \\(n_{max}, n_{max}\\).</p> <p>The lower traingular terms are made of the cosine terms</p>"},{"location":"theory/#left-s-c-right-backslash-format","title":"\\(\\left / S | C \\right \\backslash\\) format","text":"<p>This is yet another popular format where the sine-coefficients are flipped from left to right, to obtain a triangular arrangement which is completed by zeros.</p> <p>The following figure illustrates the  \\(\\left | C \\backslash S \\right |\\) and  \\(\\left / S | C \\right \\backslash\\) format respectively.</p> <p></p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>In order to make getting started with PySHBundle simple, we have curated a set of introductory tutorials in form of jupyter notebooks. Data for trying out this new tool is included in the repo. After installing and cloning the repo, go to the notebooks directory in order to find explainatory ipython jupyter notebooks. Simply activate the virtual environment and fire up these jupyter notebooks. The following notebooks explain the usage of the tool aswell as some crucial basics of Spherical Harmonics processing for Grace.</p> <ol> <li>Introduction to Spherical Harmonics</li> <li>Loading the data</li> <li>Visualizations</li> <li>Terrestrial Water Storage (TWS) Time Series</li> <li>Tests and Validation notebook</li> </ol>"}]}